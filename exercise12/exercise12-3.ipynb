{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve with embedding\n",
    "<img src='ex12-3.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1d98e47f90>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(99999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e', 'h', 'i', 'l', 'o'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = 'hihello'\n",
    "full_data = set([i for i in full_data])\n",
    "full_data # Try minor change in arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {'e': 0, 'h': 1, 'i': 2, 'l': 3, 'o': 4}\n",
    "embeds = nn.Embedding(5, 5) # 5 chars, 5 dimensions\n",
    "\n",
    "x_data = 'hihell'\n",
    "\n",
    "lookup_tensor = torch.tensor([word_to_ix[i] for i in x_data], dtype=torch.long)\n",
    "inputs = embeds(lookup_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 1, 0, 3, 3])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0195,  0.2725,  0.2672, -2.0831, -0.9972],\n",
       "        [ 0.9105, -0.7068,  1.2200, -0.0353,  0.5045],\n",
       "        [-1.0195,  0.2725,  0.2672, -2.0831, -0.9972],\n",
       "        [ 0.2432, -0.0211,  0.7164, -0.5276,  0.0104],\n",
       "        [-0.9600, -0.7599,  0.5004, -0.4419,  0.2254],\n",
       "        [-0.9600, -0.7599,  0.5004, -0.4419,  0.2254]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to do this. Otherwise `AutoGrad` will be `Embedding` not mine\n",
    "inputs = inputs.clone().detach()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [word_to_ix[i] for i in 'ihello']\n",
    "labels = torch.tensor(tmp, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 0, 3, 3, 4])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "input_size = 5  # one_hot size\n",
    "hidden_size = 5 # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1  # one sentence\n",
    "sequence_length = 1 # Let's do one by one\n",
    "num_layers = 1  # one-layer rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_size=5,\n",
    "                hidden_size=5,\n",
    "                num_layers=1,\n",
    "                batch_size=1,\n",
    "                sequence_length=1,\n",
    "                num_classes=5):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size,\n",
    "                         hidden_size=hidden_size,\n",
    "                         batch_first=True)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Fully-Connected layer\n",
    "        self.fc = nn.Linear(num_classes, num_classes)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Reshape input in (batch_size, sequence_length, input_size)\n",
    "        x = x.view(self.batch_size, self.sequence_length, self.input_size)\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out) # Add here\n",
    "        out = out.view(-1, self.num_classes)\n",
    "        return hidden, out\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Criterion & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size=5, hidden_size=5, num_layers=1, \n",
    "              batch_size=1, sequence_length=6, num_classes=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.init_hidden()\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.5181742906570435\n",
      "Predicted string: lhllll\n",
      "epoch: 1, loss: 1.472831130027771\n",
      "Predicted string: llllll\n",
      "epoch: 2, loss: 1.3394774198532104\n",
      "Predicted string: llllll\n",
      "epoch: 3, loss: 1.096235752105713\n",
      "Predicted string: lhelll\n",
      "epoch: 4, loss: 0.8429825901985168\n",
      "Predicted string: ihehlo\n",
      "epoch: 5, loss: 0.6725465655326843\n",
      "Predicted string: ihehlo\n",
      "epoch: 6, loss: 0.5581628084182739\n",
      "Predicted string: ihello\n",
      "epoch: 7, loss: 0.4689774215221405\n",
      "Predicted string: ihello\n",
      "epoch: 8, loss: 0.39387795329093933\n",
      "Predicted string: ihello\n",
      "epoch: 9, loss: 0.32651111483573914\n",
      "Predicted string: ihello\n",
      "epoch: 10, loss: 0.2684680223464966\n",
      "Predicted string: ihello\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for epoch in range(0, 10 + 1):\n",
    "    hidden.detach_()\n",
    "    hidden = hidden.detach()\n",
    "    hidden = hidden.clone().detach().requires_grad_(True) # New syntax from `1.0`\n",
    "    \n",
    "    hidden, outputs = model(inputs, hidden)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels) # It wraps for-loop in here\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    \n",
    "    # A bit acrobatic since I lookup `value` to see the `key`\n",
    "    result_str = [list(word_to_ix.keys())[list(word_to_ix.values()).index(i)] for i in idx]\n",
    "    print(f\"epoch: {epoch}, loss: {loss.data}\")\n",
    "    print(f\"Predicted string: {''.join(result_str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
