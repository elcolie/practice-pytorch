{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve with embedding\n",
    "<img src='ex12-3.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1d98e47f90>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(999999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e', 'h', 'i', 'l', 'o'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = 'hihello'\n",
    "full_data = set([i for i in full_data])\n",
    "full_data # Try minor change in arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {'e': 0, 'h': 1, 'i': 2, 'l': 3, 'o': 4}\n",
    "embeds = nn.Embedding(5, 5) # 5 chars, 5 dimensions\n",
    "\n",
    "x_data = 'hihell'\n",
    "\n",
    "lookup_tensor = torch.tensor([word_to_ix[i] for i in x_data], dtype=torch.long)\n",
    "inputs = embeds(lookup_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5680, -0.6124,  2.8113, -0.5173, -0.3163],\n",
       "        [ 0.0268, -1.6622, -0.3501, -0.7815,  0.8334],\n",
       "        [ 1.5680, -0.6124,  2.8113, -0.5173, -0.3163],\n",
       "        [ 0.4023, -0.6747, -1.4315,  1.0956,  0.9050],\n",
       "        [ 1.7756,  0.9900,  0.1204,  0.6238,  0.7079],\n",
       "        [ 1.7756,  0.9900,  0.1204,  0.6238,  0.7079]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to do this. Otherwise `AutoGrad` will be `Embedding` not mine\n",
    "inputs = inputs.clone().detach()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [word_to_ix[i] for i in 'ihello']\n",
    "labels = torch.tensor(tmp, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 0, 3, 3, 4])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "input_size = 5  # one_hot size\n",
    "hidden_size = 5 # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1  # one sentence\n",
    "sequence_length = 1 # Let's do one by one\n",
    "num_layers = 1  # one-layer rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_size=5,\n",
    "                hidden_size=5,\n",
    "                num_layers=1,\n",
    "                batch_size=1,\n",
    "                sequence_length=1,\n",
    "                num_classes=5):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size,\n",
    "                         hidden_size=hidden_size,\n",
    "                         batch_first=True)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Fully-Connected layer\n",
    "        self.fc = nn.Linear(num_classes, num_classes)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Reshape input in (batch_size, sequence_length, input_size)\n",
    "        x = x.view(self.batch_size, self.sequence_length, self.input_size)\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out) # Add here\n",
    "        out = out.view(-1, self.num_classes)\n",
    "        return hidden, out\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Criterion & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size=5, hidden_size=5, num_layers=1, \n",
    "              batch_size=1, sequence_length=6, num_classes=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.init_hidden()\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.6794244050979614\n",
      "Predicted string: hoeolh\n",
      "epoch: 1, loss: 1.268625259399414\n",
      "Predicted string: hohlll\n",
      "epoch: 2, loss: 1.0309405326843262\n",
      "Predicted string: hihlll\n",
      "epoch: 3, loss: 0.8349608778953552\n",
      "Predicted string: hihllo\n",
      "epoch: 4, loss: 0.688709557056427\n",
      "Predicted string: eihllo\n",
      "epoch: 5, loss: 0.5810956358909607\n",
      "Predicted string: eiello\n",
      "epoch: 6, loss: 0.48993992805480957\n",
      "Predicted string: eiello\n",
      "epoch: 7, loss: 0.4031357765197754\n",
      "Predicted string: eihllo\n",
      "epoch: 8, loss: 0.32734414935112\n",
      "Predicted string: eihllo\n",
      "epoch: 9, loss: 0.25418564677238464\n",
      "Predicted string: eihllo\n",
      "epoch: 10, loss: 0.18673940002918243\n",
      "Predicted string: eihllo\n",
      "epoch: 11, loss: 0.13999824225902557\n",
      "Predicted string: eihllo\n",
      "epoch: 12, loss: 0.10653456300497055\n",
      "Predicted string: eihllo\n",
      "epoch: 13, loss: 0.08126533031463623\n",
      "Predicted string: eihllo\n",
      "epoch: 14, loss: 0.06213613227009773\n",
      "Predicted string: eihllo\n",
      "epoch: 15, loss: 0.047905366867780685\n",
      "Predicted string: eihllo\n",
      "epoch: 16, loss: 0.03753829002380371\n",
      "Predicted string: eihllo\n",
      "epoch: 17, loss: 0.03005870245397091\n",
      "Predicted string: eihllo\n",
      "epoch: 18, loss: 0.02461973764002323\n",
      "Predicted string: eihllo\n",
      "epoch: 19, loss: 0.020582357421517372\n",
      "Predicted string: eihllo\n",
      "epoch: 20, loss: 0.017511367797851562\n",
      "Predicted string: eihllo\n",
      "epoch: 21, loss: 0.015120347030460835\n",
      "Predicted string: eihllo\n",
      "epoch: 22, loss: 0.013220866210758686\n",
      "Predicted string: eihllo\n",
      "epoch: 23, loss: 0.011685609817504883\n",
      "Predicted string: eihllo\n",
      "epoch: 24, loss: 0.010426044464111328\n",
      "Predicted string: eihllo\n",
      "epoch: 25, loss: 0.009379307739436626\n",
      "Predicted string: eihllo\n",
      "epoch: 26, loss: 0.00849954318255186\n",
      "Predicted string: eihllo\n",
      "epoch: 27, loss: 0.007753133773803711\n",
      "Predicted string: eihllo\n",
      "epoch: 28, loss: 0.007114330772310495\n",
      "Predicted string: eihllo\n",
      "epoch: 29, loss: 0.0065638222731649876\n",
      "Predicted string: eihllo\n",
      "epoch: 30, loss: 0.006086667533963919\n",
      "Predicted string: eihllo\n",
      "epoch: 31, loss: 0.005670865532010794\n",
      "Predicted string: eihllo\n",
      "epoch: 32, loss: 0.005307277198880911\n",
      "Predicted string: eihllo\n",
      "epoch: 33, loss: 0.004988113883882761\n",
      "Predicted string: eihllo\n",
      "epoch: 34, loss: 0.004707018379122019\n",
      "Predicted string: eihllo\n",
      "epoch: 35, loss: 0.004459063056856394\n",
      "Predicted string: eihllo\n",
      "epoch: 36, loss: 0.004239320755004883\n",
      "Predicted string: eihllo\n",
      "epoch: 37, loss: 0.0040439763106405735\n",
      "Predicted string: eihllo\n",
      "epoch: 38, loss: 0.0038693745154887438\n",
      "Predicted string: eihllo\n",
      "epoch: 39, loss: 0.0037123362999409437\n",
      "Predicted string: eihllo\n",
      "epoch: 40, loss: 0.0035699207801371813\n",
      "Predicted string: eihllo\n",
      "epoch: 41, loss: 0.0034400622826069593\n",
      "Predicted string: eihllo\n",
      "epoch: 42, loss: 0.0033207733649760485\n",
      "Predicted string: eihllo\n",
      "epoch: 43, loss: 0.0032104651909321547\n",
      "Predicted string: eihllo\n",
      "epoch: 44, loss: 0.0031082630157470703\n",
      "Predicted string: eihllo\n",
      "epoch: 45, loss: 0.0030132930260151625\n",
      "Predicted string: eihllo\n",
      "epoch: 46, loss: 0.0029252369422465563\n",
      "Predicted string: eihllo\n",
      "epoch: 47, loss: 0.0028434593696147203\n",
      "Predicted string: eihllo\n",
      "epoch: 48, loss: 0.002767721889540553\n",
      "Predicted string: eihllo\n",
      "epoch: 49, loss: 0.0026977856177836657\n",
      "Predicted string: eihllo\n",
      "epoch: 50, loss: 0.002633253810927272\n",
      "Predicted string: eihllo\n",
      "epoch: 51, loss: 0.002573807956650853\n",
      "Predicted string: eihllo\n",
      "epoch: 52, loss: 0.0025192101020365953\n",
      "Predicted string: eihllo\n",
      "epoch: 53, loss: 0.0024689834099262953\n",
      "Predicted string: eihllo\n",
      "epoch: 54, loss: 0.002422809600830078\n",
      "Predicted string: eihllo\n",
      "epoch: 55, loss: 0.0023801326751708984\n",
      "Predicted string: eihllo\n",
      "epoch: 56, loss: 0.002341032028198242\n",
      "Predicted string: eihllo\n",
      "epoch: 57, loss: 0.002304633380845189\n",
      "Predicted string: eihllo\n",
      "epoch: 58, loss: 0.0022707779426127672\n",
      "Predicted string: eihllo\n",
      "epoch: 59, loss: 0.0022393863182514906\n",
      "Predicted string: eihllo\n",
      "epoch: 60, loss: 0.0022097427863627672\n",
      "Predicted string: eihllo\n",
      "epoch: 61, loss: 0.0021820068359375\n",
      "Predicted string: eihllo\n",
      "epoch: 62, loss: 0.002155383350327611\n",
      "Predicted string: eihllo\n",
      "epoch: 63, loss: 0.002130190609022975\n",
      "Predicted string: eihllo\n",
      "epoch: 64, loss: 0.0021063487511128187\n",
      "Predicted string: eihllo\n",
      "epoch: 65, loss: 0.002083380939438939\n",
      "Predicted string: eihllo\n",
      "epoch: 66, loss: 0.0020612080115824938\n",
      "Predicted string: eihllo\n",
      "epoch: 67, loss: 0.0020399093627929688\n",
      "Predicted string: eihllo\n",
      "epoch: 68, loss: 0.0020194847602397203\n",
      "Predicted string: eihllo\n",
      "epoch: 69, loss: 0.0019996166229248047\n",
      "Predicted string: eihllo\n",
      "epoch: 70, loss: 0.0019805431365966797\n",
      "Predicted string: eihllo\n",
      "epoch: 71, loss: 0.0019620258826762438\n",
      "Predicted string: eihllo\n",
      "epoch: 72, loss: 0.0019441446056589484\n",
      "Predicted string: eihllo\n",
      "epoch: 73, loss: 0.0019267400493845344\n",
      "Predicted string: eihllo\n",
      "epoch: 74, loss: 0.0019098123302683234\n",
      "Predicted string: eihllo\n",
      "epoch: 75, loss: 0.0018935203552246094\n",
      "Predicted string: eihllo\n",
      "epoch: 76, loss: 0.0018773078918457031\n",
      "Predicted string: eihllo\n",
      "epoch: 77, loss: 0.0018617311725392938\n",
      "Predicted string: eihllo\n",
      "epoch: 78, loss: 0.0018466314068064094\n",
      "Predicted string: eihllo\n",
      "epoch: 79, loss: 0.0018315315246582031\n",
      "Predicted string: eihllo\n",
      "epoch: 80, loss: 0.0018167495727539062\n",
      "Predicted string: eihllo\n",
      "epoch: 81, loss: 0.0018024444580078125\n",
      "Predicted string: eihllo\n",
      "epoch: 82, loss: 0.0017882982501760125\n",
      "Predicted string: eihllo\n",
      "epoch: 83, loss: 0.0017743110656738281\n",
      "Predicted string: eihllo\n",
      "epoch: 84, loss: 0.0017604827880859375\n",
      "Predicted string: eihllo\n",
      "epoch: 85, loss: 0.00174713134765625\n",
      "Predicted string: eihllo\n",
      "epoch: 86, loss: 0.0017337799072265625\n",
      "Predicted string: eihllo\n",
      "epoch: 87, loss: 0.0017207463970407844\n",
      "Predicted string: eihllo\n",
      "epoch: 88, loss: 0.0017078717937693\n",
      "Predicted string: eihllo\n",
      "epoch: 89, loss: 0.0016950765857473016\n",
      "Predicted string: eihllo\n",
      "epoch: 90, loss: 0.0016826788196340203\n",
      "Predicted string: eihllo\n",
      "epoch: 91, loss: 0.0016703605651855469\n",
      "Predicted string: eihllo\n",
      "epoch: 92, loss: 0.001658280729316175\n",
      "Predicted string: eihllo\n",
      "epoch: 93, loss: 0.001646280288696289\n",
      "Predicted string: eihllo\n",
      "epoch: 94, loss: 0.0016346772899851203\n",
      "Predicted string: eihllo\n",
      "epoch: 95, loss: 0.001622915267944336\n",
      "Predicted string: eihllo\n",
      "epoch: 96, loss: 0.0016113122692331672\n",
      "Predicted string: eihllo\n",
      "epoch: 97, loss: 0.0016001859912648797\n",
      "Predicted string: eihllo\n",
      "epoch: 98, loss: 0.001589059829711914\n",
      "Predicted string: eihllo\n",
      "epoch: 99, loss: 0.0015778541564941406\n",
      "Predicted string: eihllo\n",
      "epoch: 100, loss: 0.0015669664135202765\n",
      "Predicted string: eihllo\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for epoch in range(0, 100 + 1):\n",
    "    hidden.detach_()\n",
    "    hidden = hidden.detach()\n",
    "    hidden = hidden.clone().detach().requires_grad_(True) # New syntax from `1.0`\n",
    "    \n",
    "    hidden, outputs = model(inputs, hidden)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels) # It wraps for-loop in here\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    print(f\"epoch: {epoch}, loss: {loss.data}\")\n",
    "    print(f\"Predicted string: {''.join(result_str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
