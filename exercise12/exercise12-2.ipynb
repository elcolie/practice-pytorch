{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='ex12-2.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_lookup = [\n",
    "    [1, 0, 0, 0, 0], # 0 h\n",
    "    [0, 1, 0, 0, 0], # 1 i\n",
    "    [0, 0, 1, 0, 0], # 2 e\n",
    "    [0, 0, 0, 1, 0], # 3 l\n",
    "    [0, 0, 0, 0, 1], # 4 o\n",
    "]\n",
    "x_data = [0, 1, 0, 2, 3, 3] # hihell\n",
    "y_data = [1, 0, 2, 3, 3, 4] # ihello\n",
    "x_one_hot = [one_hot_lookup[i] for i in x_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "input_size = 5  # one_hot size\n",
    "hidden_size = 5 # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1  # one sentence\n",
    "sequence_length = 1 # Let's do one by one\n",
    "num_layers = 1  # one-layer rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(x_one_hot, dtype=torch.float)\n",
    "labels = torch.tensor(y_data, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_size=5,\n",
    "                hidden_size=5,\n",
    "                num_layers=1,\n",
    "                batch_size=1,\n",
    "                sequence_length=1,\n",
    "                num_classes=5):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size,\n",
    "                         hidden_size=hidden_size,\n",
    "                         batch_first=True)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Fully-Connected layer\n",
    "        self.fc = nn.Linear(num_classes, num_classes)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Reshape input in (batch_size, sequence_length, input_size)\n",
    "        x = x.view(self.batch_size, self.sequence_length, self.input_size)\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out) # Add here\n",
    "        out = out.view(-1, self.num_classes)\n",
    "        return hidden, out\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Criterion & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size=5, hidden_size=5, num_layers=1, batch_size=1, sequence_length=6, num_classes=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.init_hidden()\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "x_data = [0, 1, 0, 2, 3, 3] # hihell\n",
    "one_hot_dict = {\n",
    "    'h': [1, 0, 0, 0, 0],\n",
    "    'i': [0, 1, 0, 0, 0],\n",
    "    'e': [0, 0, 1, 0, 0],\n",
    "    'l': [0, 0, 0, 1, 0],\n",
    "    'o': [0, 0, 0, 0, 1],\n",
    "}\n",
    "one_hot_lookup = [\n",
    "    [1, 0, 0, 0, 0], # 0 h\n",
    "    [0, 1, 0, 0, 0], # 1 i\n",
    "    [0, 0, 1, 0, 0], # 2 e\n",
    "    [0, 0, 0, 1, 0], # 3 l\n",
    "    [0, 0, 0, 0, 1], # 4 o\n",
    "]\n",
    "y_data = [1, 0, 2, 3, 3, 4] # ihello\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(x_one_hot, dtype=torch.float)\n",
    "labels = torch.tensor(y_data, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 2, 3, 3, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: loss.data\n",
      "Predicted string: oooooo\n",
      "epoch: 1, loss: loss.data\n",
      "Predicted string: llllll\n",
      "epoch: 2, loss: loss.data\n",
      "Predicted string: lhllll\n",
      "epoch: 3, loss: loss.data\n",
      "Predicted string: ihilll\n",
      "epoch: 4, loss: loss.data\n",
      "Predicted string: ihilll\n",
      "epoch: 5, loss: loss.data\n",
      "Predicted string: ihilll\n",
      "epoch: 6, loss: loss.data\n",
      "Predicted string: ihilll\n",
      "epoch: 7, loss: loss.data\n",
      "Predicted string: ihelll\n",
      "epoch: 8, loss: loss.data\n",
      "Predicted string: ihelll\n",
      "epoch: 9, loss: loss.data\n",
      "Predicted string: ehelll\n",
      "epoch: 10, loss: loss.data\n",
      "Predicted string: ehello\n",
      "epoch: 11, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 12, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 13, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 14, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 15, loss: loss.data\n",
      "Predicted string: ihello\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 15 + 1):\n",
    "    hidden.detach_()\n",
    "    hidden = hidden.detach()\n",
    "    hidden = hidden.clone().detach().requires_grad_(True) # New syntax from `1.0`\n",
    "    \n",
    "    hidden, outputs = model(inputs, hidden)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels) # It wraps for-loop in here\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    print(f\"epoch: {epoch}, loss: loss.data\")\n",
    "    print(f\"Predicted string: {''.join(result_str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
