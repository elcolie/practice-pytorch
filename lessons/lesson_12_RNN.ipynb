{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [1, 0, 0 ,0] # dim (4)\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dim (2)\n",
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[h]], dtype=torch.float) # rank = (1, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.randn(1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = cell(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0886, 0.5660]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfolding to `n` sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[h, e, l, l, o]]\n",
    "inputs = torch.tensor(inputs, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.randn(1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8379,  0.1169],\n",
       "         [ 0.5100,  0.3034],\n",
       "         [ 0.8857,  0.0452],\n",
       "         [ 0.8154, -0.0911],\n",
       "         [ 0.8023,  0.1019]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, hidden = cell(inputs, hidden)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batching input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RNN.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 2\n",
    "sequence_length = 5\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[h, e, l, l, o], \n",
    "          [e, o, l, l, l],\n",
    "          [l, l, e, e, l]]\n",
    "inputs = torch.tensor(inputs, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size() # (batch, seq, one_hot_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hidden_size` changed to `3` (batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.randn(1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = cell(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2943, -0.4227],\n",
       "         [ 0.6367, -0.3800],\n",
       "         [-0.7054,  0.5231],\n",
       "         [-0.8284,  0.5637],\n",
       "         [ 0.0511,  0.5185]],\n",
       "\n",
       "        [[ 0.8957, -0.3290],\n",
       "         [ 0.2561,  0.4048],\n",
       "         [-0.8674,  0.4274],\n",
       "         [-0.7936,  0.6040],\n",
       "         [-0.8390,  0.5623]],\n",
       "\n",
       "        [[-0.8232,  0.5418],\n",
       "         [-0.8239,  0.5779],\n",
       "         [ 0.1936, -0.4992],\n",
       "         [ 0.5999, -0.4525],\n",
       "         [-0.6753,  0.5427]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teach RNN `hihello` to `ihello`\n",
    "input_dim = 5<br>\n",
    "output_dim = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./55.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously loss function have to be `cross entropy`<br>\n",
    "Because it is multi classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./rnn_loss.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['h', 'i', 'e', 'l', 'o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [0, 1, 0, 2, 3, 3] # hihell\n",
    "one_hot_dict = {\n",
    "    'h': [1, 0, 0, 0, 0],\n",
    "    'i': [0, 1, 0, 0, 0],\n",
    "    'e': [0, 0, 1, 0, 0],\n",
    "    'l': [0, 0, 0, 1, 0],\n",
    "    'o': [0, 0, 0, 0, 1],\n",
    "}\n",
    "one_hot_lookup = [\n",
    "    [1, 0, 0, 0, 0], # 0 h\n",
    "    [0, 1, 0, 0, 0], # 1 i\n",
    "    [0, 0, 1, 0, 0], # 2 e\n",
    "    [0, 0, 0, 1, 0], # 3 l\n",
    "    [0, 0, 0, 0, 1], # 4 o\n",
    "]\n",
    "y_data = [1, 0, 2, 3, 3, 4] # ihello\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "input_size = 5  # one_hot size\n",
    "hidden_size = 5 # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1  # one sentence\n",
    "sequence_length = 1 # Let's do one by one\n",
    "num_layers = 1  # one-layer rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 'hihell'\n",
    "labels = 'ihello'\n",
    "ans = [one_hot_dict[i] for i in inputs]\n",
    "inputs = torch.tensor(ans, dtype=torch.float)\n",
    "labels = torch.tensor(y_data, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size=5, \n",
    "                 hidden_size=5, \n",
    "                 num_layers=1, \n",
    "                 batch_size=1, \n",
    "                 sequence_length=1,\n",
    "                 num_classes=5):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, \n",
    "                          hidden_size=hidden_size, batch_first=True)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # Reshape input in (batch_size, sequence_length, input_size)\n",
    "        x = x.view(batch_size, sequence_length, input_size)\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.view(-1, num_classes)\n",
    "        return hidden, out\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(num_layers, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Criterion & Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='loss.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training (feed one by one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.init_hidden()\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def single_traing(inputs, labels, hidden, loss, criterion, optimizer):\n",
    "    sys.stdout.write(\"predicted string: \")\n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden, output = model(input, hidden)\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        val, idx = output.max(1)\n",
    "        sys.stdout.write(idx2char[idx.data[0]])\n",
    "        my_label = label.unsqueeze(0)\n",
    "        loss += criterion(output, my_label)\n",
    "    print(f\"\\t epoch: {epoch}, loss: {loss.data}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted string: ihello\t epoch: 4, loss: 2.681422472000122\n"
     ]
    }
   ],
   "source": [
    "single_traing(inputs, labels, hidden, loss, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Training with epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted string: hhihhh\t epoch: 1, loss: 9.099803924560547\n",
      "predicted string: lhelhl\t epoch: 2, loss: 7.887807846069336\n",
      "predicted string: ihilll\t epoch: 3, loss: 6.988587379455566\n",
      "predicted string: ihillo\t epoch: 4, loss: 6.244536399841309\n",
      "predicted string: ihello\t epoch: 5, loss: 5.607056140899658\n",
      "predicted string: ihello\t epoch: 6, loss: 5.096649169921875\n",
      "predicted string: ihello\t epoch: 7, loss: 4.712426662445068\n",
      "predicted string: ihelho\t epoch: 8, loss: 4.428897857666016\n",
      "predicted string: ihelho\t epoch: 9, loss: 4.216862201690674\n",
      "predicted string: ihello\t epoch: 10, loss: 4.049167633056641\n",
      "predicted string: ihello\t epoch: 11, loss: 3.9077630043029785\n",
      "predicted string: ihello\t epoch: 12, loss: 3.784339189529419\n",
      "predicted string: ihello\t epoch: 13, loss: 3.6682534217834473\n",
      "predicted string: ihello\t epoch: 14, loss: 3.54925274848938\n",
      "predicted string: ihello\t epoch: 15, loss: 3.4397172927856445\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 15 + 1):\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = model.init_hidden()\n",
    "    single_traing(inputs, labels, hidden, loss, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
