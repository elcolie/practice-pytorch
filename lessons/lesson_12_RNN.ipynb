{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [1, 0, 0 ,0] # dim (4)\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dim (2)\n",
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[h]], dtype=torch.float) # rank = (1, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.randn(1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = cell(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0886, 0.5660]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfolding to `n` sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[h, e, l, l, o]]\n",
    "inputs = torch.tensor(inputs, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.randn(1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8379,  0.1169],\n",
       "         [ 0.5100,  0.3034],\n",
       "         [ 0.8857,  0.0452],\n",
       "         [ 0.8154, -0.0911],\n",
       "         [ 0.8023,  0.1019]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, hidden = cell(inputs, hidden)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batching input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RNN.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 2\n",
    "sequence_length = 5\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[h, e, l, l, o], \n",
    "          [e, o, l, l, l],\n",
    "          [l, l, e, e, l]]\n",
    "inputs = torch.tensor(inputs, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size() # (batch, seq, one_hot_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hidden_size` changed to `3` (batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.randn(1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = cell(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2943, -0.4227],\n",
       "         [ 0.6367, -0.3800],\n",
       "         [-0.7054,  0.5231],\n",
       "         [-0.8284,  0.5637],\n",
       "         [ 0.0511,  0.5185]],\n",
       "\n",
       "        [[ 0.8957, -0.3290],\n",
       "         [ 0.2561,  0.4048],\n",
       "         [-0.8674,  0.4274],\n",
       "         [-0.7936,  0.6040],\n",
       "         [-0.8390,  0.5623]],\n",
       "\n",
       "        [[-0.8232,  0.5418],\n",
       "         [-0.8239,  0.5779],\n",
       "         [ 0.1936, -0.4992],\n",
       "         [ 0.5999, -0.4525],\n",
       "         [-0.6753,  0.5427]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teach RNN `hihello` to `ihello`\n",
    "input_dim = 5<br>\n",
    "output_dim = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./55.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously loss function have to be `cross entropy`<br>\n",
    "Because it is multi classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./rnn_loss.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['h', 'i', 'e', 'l', 'o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [0, 1, 0, 2, 3, 3] # hihell\n",
    "one_hot_dict = {\n",
    "    'h': [1, 0, 0, 0, 0],\n",
    "    'i': [0, 1, 0, 0, 0],\n",
    "    'e': [0, 0, 1, 0, 0],\n",
    "    'l': [0, 0, 0, 1, 0],\n",
    "    'o': [0, 0, 0, 0, 1],\n",
    "}\n",
    "one_hot_lookup = [\n",
    "    [1, 0, 0, 0, 0], # 0 h\n",
    "    [0, 1, 0, 0, 0], # 1 i\n",
    "    [0, 0, 1, 0, 0], # 2 e\n",
    "    [0, 0, 0, 1, 0], # 3 l\n",
    "    [0, 0, 0, 0, 1], # 4 o\n",
    "]\n",
    "y_data = [1, 0, 2, 3, 3, 4] # ihello\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "input_size = 5  # one_hot size\n",
    "hidden_size = 5 # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1  # one sentence\n",
    "sequence_length = 1 # Let's do one by one\n",
    "num_layers = 1  # one-layer rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 'hihell'\n",
    "labels = 'ihello'\n",
    "ans = [one_hot_dict[i] for i in inputs]\n",
    "inputs = torch.tensor(ans, dtype=torch.float)\n",
    "labels = torch.tensor(y_data, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size=5, \n",
    "                 hidden_size=5, \n",
    "                 num_layers=1, \n",
    "                 batch_size=1, \n",
    "                 sequence_length=1,\n",
    "                 num_classes=5):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, \n",
    "                          hidden_size=hidden_size, batch_first=True)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # Reshape input in (batch_size, sequence_length, input_size)\n",
    "        x = x.view(self.batch_size, self.sequence_length, self.input_size)\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.view(-1, self.num_classes)\n",
    "        return hidden, out\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Criterion & Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='loss.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training (feed one by one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.init_hidden()\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def single_traing(inputs, labels, hidden, loss, criterion, optimizer, epoch):\n",
    "    sys.stdout.write(\"predicted string: \")\n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden, output = model(input, hidden)\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        val, idx = output.max(1)\n",
    "        sys.stdout.write(idx2char[idx.data[0]])\n",
    "        my_label = label.unsqueeze(0)\n",
    "        loss += criterion(output, my_label)\n",
    "    print(f\"\\t epoch: {epoch}, loss: {loss.data}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted string: oooooo\t epoch: 1, loss: 9.67501449584961\n"
     ]
    }
   ],
   "source": [
    "single_traing(inputs, labels, hidden, loss, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Training with epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted string: llelol\t epoch: 1, loss: 8.346803665161133\n",
      "predicted string: llelll\t epoch: 2, loss: 7.710038185119629\n",
      "predicted string: lhelll\t epoch: 3, loss: 7.078332424163818\n",
      "predicted string: ihelll\t epoch: 4, loss: 6.411087989807129\n",
      "predicted string: ihelll\t epoch: 5, loss: 5.867803573608398\n",
      "predicted string: ihello\t epoch: 6, loss: 5.449371337890625\n",
      "predicted string: ihello\t epoch: 7, loss: 5.100369453430176\n",
      "predicted string: ihello\t epoch: 8, loss: 4.8028035163879395\n",
      "predicted string: ihello\t epoch: 9, loss: 4.539853096008301\n",
      "predicted string: ihello\t epoch: 10, loss: 4.322007656097412\n",
      "predicted string: ihello\t epoch: 11, loss: 4.153645992279053\n",
      "predicted string: ihello\t epoch: 12, loss: 4.020106792449951\n",
      "predicted string: ihello\t epoch: 13, loss: 3.906681537628174\n",
      "predicted string: ihello\t epoch: 14, loss: 3.794679880142212\n",
      "predicted string: ihello\t epoch: 15, loss: 3.658536672592163\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 15 + 1):\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = model.init_hidden()\n",
    "    single_traing(inputs, labels, hidden, loss, criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traing with Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size=5, hidden_size=5, num_layers=1, batch_size=1, sequence_length=6, num_classes=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.init_hidden()\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "x_data = [0, 1, 0, 2, 3, 3] # hihell\n",
    "one_hot_dict = {\n",
    "    'h': [1, 0, 0, 0, 0],\n",
    "    'i': [0, 1, 0, 0, 0],\n",
    "    'e': [0, 0, 1, 0, 0],\n",
    "    'l': [0, 0, 0, 1, 0],\n",
    "    'o': [0, 0, 0, 0, 1],\n",
    "}\n",
    "one_hot_lookup = [\n",
    "    [1, 0, 0, 0, 0], # 0 h\n",
    "    [0, 1, 0, 0, 0], # 1 i\n",
    "    [0, 0, 1, 0, 0], # 2 e\n",
    "    [0, 0, 0, 1, 0], # 3 l\n",
    "    [0, 0, 0, 0, 1], # 4 o\n",
    "]\n",
    "y_data = [1, 0, 2, 3, 3, 4] # ihello\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(x_one_hot, dtype=torch.float)\n",
    "labels = torch.tensor(y_data, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3872,  0.2820, -0.4500, -0.0872,  0.7308]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[ 0.7743, -0.3904, -0.3325, -0.1843,  0.4248],\n",
       "         [ 0.4862,  0.5670, -0.4613, -0.2728, -0.2374],\n",
       "         [ 0.6088, -0.2582, -0.2186, -0.3021,  0.4142],\n",
       "         [ 0.3824, -0.0154, -0.7828, -0.1554, -0.2564],\n",
       "         [ 0.4786,  0.4957,  0.0216,  0.0599,  0.7219],\n",
       "         [ 0.3872,  0.2820, -0.4500, -0.0872,  0.7308]], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden, output\n",
    "model(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: loss.data\n",
      "Predicted string: llllil\n",
      "epoch: 1, loss: loss.data\n",
      "Predicted string: llllll\n",
      "epoch: 2, loss: loss.data\n",
      "Predicted string: llllll\n",
      "epoch: 3, loss: loss.data\n",
      "Predicted string: llilll\n",
      "epoch: 4, loss: loss.data\n",
      "Predicted string: ihiloo\n",
      "epoch: 5, loss: loss.data\n",
      "Predicted string: ihiloo\n",
      "epoch: 6, loss: loss.data\n",
      "Predicted string: ihiloo\n",
      "epoch: 7, loss: loss.data\n",
      "Predicted string: ihillo\n",
      "epoch: 8, loss: loss.data\n",
      "Predicted string: ihillo\n",
      "epoch: 9, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 10, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 11, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 12, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 13, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 14, loss: loss.data\n",
      "Predicted string: ihello\n",
      "epoch: 15, loss: loss.data\n",
      "Predicted string: ihello\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 15 + 1):\n",
    "    hidden.detach_()\n",
    "    hidden = hidden.detach()\n",
    "    hidden = hidden.clone().detach().requires_grad_(True) # New syntax from `1.0`\n",
    "    \n",
    "    hidden, outputs = model(inputs, hidden)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels) # It wraps for-loop in here\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    print(f\"epoch: {epoch}, loss: loss.data\")\n",
    "    print(f\"Predicted string: {''.join(result_str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
