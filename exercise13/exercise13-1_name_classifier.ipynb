{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement name classifier\n",
    "1. With `GPU`\n",
    "2. With `data parallel`\n",
    "3. Use `pad-pack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from utils import *\n",
    "\n",
    "torch.manual_seed(1249583)\n",
    "\n",
    "# See the details in `Dataset` section\n",
    "SEQUENCE_LENGTH = 19\n",
    "COUNTRY_LENGTH = 18\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, criterion):\n",
    "    \"\"\"\n",
    "    This function has one line different from the ordinary `train()` function\n",
    "    It has `make_variables()` to convert tuple of names to be a tensor\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        import ipdb; ipdb.set_trace()\n",
    "\n",
    "        data, lengths = ordered_batch(data)\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        tmp = output.view(-1, COUNTRY_LENGTH)\n",
    "        loss = criterion(tmp, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            \"\"\"\n",
    "            Will be next\n",
    "            \"\"\"\n",
    "            data = make_variables(data)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            tmp = output.view(-1, COUNTRY_LENGTH)\n",
    "            \n",
    "            test_loss += criterion(tmp, target).item() # sum up batch loss\n",
    "            pred = tmp.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "            pred_tmp = pred.view(-1)\n",
    "            pred_list = pred_tmp.tolist()\n",
    "            target_list = target.tolist()\n",
    "            \n",
    "            y_test += target_list\n",
    "            y_pred += pred_list\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(confusion_mtx, classes=countries, normalize=True,\n",
    "                          title='Confusion matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[116, 105, 114,  97, 115],\n",
       "         [ 97, 110, 110,   0,   0],\n",
       "         [101, 108,   0,   0,   0]]), [5, 3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp, lengths = ordered_batch(['Tiras', 'Ann', 'El'])\n",
    "tmp, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(128, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3663, -1.6736, -1.5389, -0.7287,  0.2120],\n",
       "         [ 0.4269, -1.8379,  1.8960, -0.8565,  0.3572],\n",
       "         [-0.9517, -1.1371,  1.5963,  0.3610,  0.7760],\n",
       "         [ 0.0619,  2.4133,  2.6724,  0.5250, -0.1814],\n",
       "         [-0.0545, -1.4245,  1.9233,  0.6525,  0.3656]],\n",
       "\n",
       "        [[ 0.0619,  2.4133,  2.6724,  0.5250, -0.1814],\n",
       "         [-0.6600,  0.4255, -0.4647,  0.7076,  0.8170],\n",
       "         [-0.6600,  0.4255, -0.4647,  0.7076,  0.8170],\n",
       "         [ 0.3030, -0.2241,  1.9057,  1.2253,  0.0273],\n",
       "         [ 0.3030, -0.2241,  1.9057,  1.2253,  0.0273]],\n",
       "\n",
       "        [[-0.3473,  1.7434,  1.8095,  0.2949, -0.2356],\n",
       "         [ 0.0537,  2.5934,  0.3567,  1.0987,  1.1411],\n",
       "         [ 0.3030, -0.2241,  1.9057,  1.2253,  0.0273],\n",
       "         [ 0.3030, -0.2241,  1.9057,  1.2253,  0.0273],\n",
       "         [ 0.3030, -0.2241,  1.9057,  1.2253,  0.0273]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = emb(tmp)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.3663, -1.6736, -1.5389, -0.7287,  0.2120],\n",
       "        [ 0.0619,  2.4133,  2.6724,  0.5250, -0.1814],\n",
       "        [-0.3473,  1.7434,  1.8095,  0.2949, -0.2356],\n",
       "        [ 0.4269, -1.8379,  1.8960, -0.8565,  0.3572],\n",
       "        [-0.6600,  0.4255, -0.4647,  0.7076,  0.8170],\n",
       "        [ 0.0537,  2.5934,  0.3567,  1.0987,  1.1411],\n",
       "        [-0.9517, -1.1371,  1.5963,  0.3610,  0.7760],\n",
       "        [-0.6600,  0.4255, -0.4647,  0.7076,  0.8170],\n",
       "        [ 0.0619,  2.4133,  2.6724,  0.5250, -0.1814],\n",
       "        [-0.0545, -1.4245,  1.9233,  0.6525,  0.3656]],\n",
       "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([3, 3, 2, 1, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pps_in = torch.nn.utils.rnn.pack_padded_sequence(embedding, batch_first=True, lengths=lengths)\n",
    "pps_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3663, -1.6736, -1.5389, -0.7287,  0.2120],\n",
       "          [ 0.4269, -1.8379,  1.8960, -0.8565,  0.3572],\n",
       "          [-0.9517, -1.1371,  1.5963,  0.3610,  0.7760],\n",
       "          [ 0.0619,  2.4133,  2.6724,  0.5250, -0.1814],\n",
       "          [-0.0545, -1.4245,  1.9233,  0.6525,  0.3656]],\n",
       " \n",
       "         [[ 0.0619,  2.4133,  2.6724,  0.5250, -0.1814],\n",
       "          [-0.6600,  0.4255, -0.4647,  0.7076,  0.8170],\n",
       "          [-0.6600,  0.4255, -0.4647,  0.7076,  0.8170],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.3473,  1.7434,  1.8095,  0.2949, -0.2356],\n",
       "          [ 0.0537,  2.5934,  0.3567,  1.0987,  1.1411],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "        grad_fn=<TransposeBackward0>), tensor([5, 3, 2]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pps_out = torch.nn.utils.rnn.pad_packed_sequence(pps_in, batch_first=True)\n",
    "pps_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(5, 18, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps_out_n_size, ht = gru(pps_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.nn.utils.rnn.pad_packed_sequence(pps_out_n_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1267,  0.0813, -0.1555,  0.1041, -0.1072, -0.1833, -0.0070,\n",
       "            0.1165, -0.1294,  0.0291,  0.0284,  0.1789,  0.0305, -0.0236,\n",
       "           -0.0580,  0.0699, -0.0144, -0.0230],\n",
       "          [ 0.1818,  0.0287, -0.2037,  0.2784, -0.1972, -0.1245, -0.0552,\n",
       "            0.1694, -0.1861,  0.0257,  0.1175,  0.2766,  0.0817, -0.0955,\n",
       "           -0.0861,  0.1076,  0.0452, -0.0568],\n",
       "          [ 0.1858,  0.0343, -0.2158,  0.2969, -0.2918, -0.0639, -0.0937,\n",
       "            0.1674, -0.1966,  0.0027,  0.1714,  0.3586,  0.0530, -0.1475,\n",
       "           -0.1228,  0.1286,  0.0940, -0.0035],\n",
       "          [ 0.1314,  0.1084, -0.0795,  0.2666, -0.2950,  0.0697, -0.0708,\n",
       "            0.1269, -0.1151,  0.0453,  0.2150,  0.2951,  0.1183, -0.0506,\n",
       "           -0.1685,  0.1065,  0.1900, -0.0055],\n",
       "          [ 0.1252,  0.0999, -0.0762,  0.2773, -0.3249,  0.1369, -0.0849,\n",
       "            0.1273, -0.1031,  0.0541,  0.2703,  0.3272,  0.1012, -0.0660,\n",
       "           -0.1749,  0.1244,  0.2232, -0.0129]],\n",
       " \n",
       "         [[ 0.0243,  0.1224,  0.0498,  0.1308, -0.0922,  0.0449,  0.0066,\n",
       "            0.0550, -0.0055,  0.0774,  0.0725,  0.0372,  0.0889,  0.0413,\n",
       "           -0.0873,  0.0697,  0.1251, -0.0057],\n",
       "          [ 0.0455,  0.2251,  0.0215,  0.1272, -0.1846, -0.0395,  0.0203,\n",
       "            0.0783, -0.0373,  0.0740,  0.0653,  0.1106,  0.0498,  0.0565,\n",
       "           -0.1208,  0.1013,  0.1290,  0.0329],\n",
       "          [ 0.0707,  0.2893, -0.0191,  0.0929, -0.2426, -0.1390,  0.0251,\n",
       "            0.0775, -0.0603,  0.0839,  0.0438,  0.1706,  0.0083,  0.0910,\n",
       "           -0.1341,  0.1129,  0.1117,  0.0683],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0422,  0.1264,  0.0142,  0.1136, -0.1029, -0.0069, -0.0020,\n",
       "            0.0588, -0.0297,  0.0723,  0.0434,  0.0629,  0.0663,  0.0437,\n",
       "           -0.0881,  0.0721,  0.0910,  0.0183],\n",
       "          [ 0.0382,  0.2419,  0.0615,  0.0822, -0.1808, -0.0561,  0.0211,\n",
       "            0.0319,  0.0035,  0.1273,  0.0205,  0.0251,  0.0807,  0.1281,\n",
       "           -0.1374,  0.0993,  0.1481,  0.0502],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<TransposeBackward0>),\n",
       " tensor([5, 3, 2]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelX(nn.Module):\n",
    "    def __init__(self, input_size=256, hidden_size=5, output_size=18, n_layers=1):\n",
    "        \"\"\"\n",
    "        Because word embedding is working with ascii. It has to use `input_size=128, hidden_size=256`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # input_size 256, hidden_size 256.\n",
    "        # https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html\n",
    "        self.embedding = nn.Embedding(128, hidden_size) # embedding_dim MUST matches with GRU's input_size \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Do not remove `print`. Leave it be a historical footprint for I myself in the future\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sung Kim run this all at once (over the whole input sequence)\n",
    "        # input = B x S . size(0) = B\n",
    "#         batch_size = input.size(0)\n",
    "        \n",
    "        # input: B x S -- (transpose) --> S x B\n",
    "#         input = input.t()\n",
    "#         import ipdb; ipdb.set_trace()\n",
    "#         ipdb> input\n",
    "#         tensor([[118,  97, 108,  99, 104, 105, 107, 111, 118, 115, 107, 105],\n",
    "#             [ 99,  97, 114, 100, 111, 122, 111,   0,   0,   0,   0,   0]])\n",
    "#         ipdb> input.size()\n",
    "#         torch.Size([2, 12])\n",
    "        input, lengths = ordered_batch(['Tiras', 'Ann', 'El'])\n",
    "\n",
    "        # Embedding S x B -> S x B x I (embedding size)\n",
    "        print(f\" input size: {input.size()}\")\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = embedded.clone().detach() # Make new tensor because of `EmbeddingGrad`\n",
    "        print(f\" embeddding size: {embedded.size()}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Make a hidden\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        \n",
    "        \n",
    "        pps_in = torch.nn.utils.rnn.pack_padded_sequence(embedded, batch_first=True, lengths=lengths)\n",
    "        packed_output, hidden = self.gru(pps_in, hidden)\n",
    "        print(f\" gru hidden output: {hidden.size()}\")\n",
    "        \n",
    "        result = torch.nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # Use last layer output as FC's input\n",
    "        # No need to unpack, since we are going to use hidden\n",
    "        fc_output = self.fc(result)\n",
    "        print(f\" fc output: {fc_output.size()}\")\n",
    "        return fc_output\n",
    "        \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        USE_CUDA = torch.cuda.is_available()\n",
    "        DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "        return hidden.clone().detach().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'str2ascii_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-f473c0b1de6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# classifier = RNNClassifier()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr2ascii_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adylov'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'str2ascii_arr' is not defined"
     ]
    }
   ],
   "source": [
    "# classifier = RNNClassifier()\n",
    "classifier = ModelX()\n",
    "arr, _ = str2ascii_arr('adylov')\n",
    "inp = torch.tensor([arr], dtype=torch.long)\n",
    "out = classifier(inp)\n",
    "print(f\"\\nin: {inp.size()}, \\nout: {out.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input size: torch.Size([6, 4])\n",
      " embeddding size: torch.Size([6, 4, 5])\n",
      " gru hidden output: torch.Size([1, 4, 5])\n",
      " fc output: torch.Size([1, 4, 18])\n",
      "\n",
      "batch in: torch.Size([4, 6]), \n",
      "batch out: torch.Size([1, 4, 18])\n"
     ]
    }
   ],
   "source": [
    "names = ['adylov', 'solan', 'hard', 'san']\n",
    "# classifier = RNNClassifier()\n",
    "classifier = ModelX()\n",
    "inputs = make_var(names)\n",
    "out = classifier(inputs)\n",
    "print(f\"\\nbatch in: {inputs.size()}, \\nbatch out: {out.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size=256, hidden_size=256, output_size=18, n_layers=1):\n",
    "        \"\"\"\n",
    "        Because word embedding is working with ascii. It has to use `input_size=128, hidden_size=256`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # input_size 256, hidden_size 256.\n",
    "        # https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html\n",
    "        self.embedding = nn.Embedding(128, hidden_size) # embedding_dim MUST matches with GRU's input_size \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Do not remove `print`. Leave it be a historical footprint for I myself in the future\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sung Kim run this all at once (over the whole input sequence)\n",
    "        # input = B x S . size(0) = B\n",
    "        batch_size = input.size(0)\n",
    "        \n",
    "        # input: B x S -- (transpose) --> S x B\n",
    "        input = input.t()\n",
    "        \n",
    "        # Embedding S x B -> S x B x I (embedding size)\n",
    "        print(f\" input size: {input.size()}\")\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = embedded.clone().detach() # Make new tensor because of `EmbeddingGrad`\n",
    "        print(f\" embeddding size: {embedded.size()}\")\n",
    "        \n",
    "        # Make a hidden\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        print(f\" gru hidden output: {hidden.size()}\")\n",
    "        \n",
    "        # Use last layer output as FC's input\n",
    "        # No need to unpack, since we are going to use hidden\n",
    "        fc_output = self.fc(hidden)\n",
    "        print(f\" fc output: {fc_output.size()}\")\n",
    "        return fc_output\n",
    "        \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        USE_CUDA = torch.cuda.is_available()\n",
    "        DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "        return hidden.clone().detach().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataSet(Dataset):\n",
    "    def __init__(self, filename='names_train.csv'):\n",
    "        trainset = pd.read_csv(filename, header=None)\n",
    "        trainset.columns = ['name', 'country']\n",
    "        countries = sorted(list(trainset.country.drop_duplicates()))\n",
    "\n",
    "        self.trainset = trainset\n",
    "        self.countries = countries\n",
    "        self.len = len(trainset)        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        country = self.trainset.iloc[index]['country']\n",
    "        return self.trainset.iloc[index]['name'], self.countries.index(country)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NameDataSet(filename='../lessons/names_train.csv')\n",
    "test_dataset = NameDataSet(filename='../lessons/names_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=2, num_workers=2) # 2 * 9 * 743 \n",
    "test_loader = DataLoader(dataset=test_dataset, sampler=ImbalancedDatasetSampler(test_dataset), batch_size=2, num_workers=2) # 4 * 25 * 67\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNNClassifier().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelX().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Criterion & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645492a5f8c644b583bed4c795ff3768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-58-0a850967a2f5>\u001b[0m(15)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     14 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m        \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mordered_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> list\n",
      "\u001b[1;32m     10 \u001b[0m    \"\"\"\n",
      "\u001b[1;32m     11 \u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     12 \u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     13 \u001b[0m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     14 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 15 \u001b[0;31m        \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mordered_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     16 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     17 \u001b[0m        \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     18 \u001b[0m        \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     19 \u001b[0m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     20 \u001b[0m        \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNTRY_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "ipdb> data\n",
      "('Cardozo', 'Valchikovski')\n",
      "ipdb> target\n",
      "tensor([13, 14])\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-58-0a850967a2f5>\u001b[0m(17)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 17 \u001b[0;31m        \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m        \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> data\n",
      "tensor([[118,  97, 108,  99, 104, 105, 107, 111, 118, 115, 107, 105],\n",
      "        [ 99,  97, 114, 100, 111, 122, 111,   0,   0,   0,   0,   0]])\n",
      "ipdb> lengths\n",
      "[12, 7]\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-58-0a850967a2f5>\u001b[0m(18)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     17 \u001b[0;31m        \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m        \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-58-0a850967a2f5>\u001b[0m(19)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     18 \u001b[0;31m        \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m        \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNTRY_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-44-565e6c4bfc5d>\u001b[0m(29)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     28 \u001b[0;31m        \u001b[0;31m# Embedding S x B -> S x B x I (embedding size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 29 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" input size: {input.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m        \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> list\n",
      "\u001b[1;32m     24 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     25 \u001b[0m        \u001b[0;31m# input: B x S -- (transpose) --> S x B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     26 \u001b[0m\u001b[0;31m#         input = input.t()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     27 \u001b[0m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     28 \u001b[0m        \u001b[0;31m# Embedding S x B -> S x B x I (embedding size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 29 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" input size: {input.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     30 \u001b[0m        \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     31 \u001b[0m        \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Make new tensor because of `EmbeddingGrad`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     32 \u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" embeddding size: {embedded.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     33 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     34 \u001b[0m        \u001b[0;31m# Make a hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "ipdb> input\n",
      "tensor([[118,  97, 108,  99, 104, 105, 107, 111, 118, 115, 107, 105],\n",
      "        [ 99,  97, 114, 100, 111, 122, 111,   0,   0,   0,   0,   0]])\n",
      "ipdb> input.size()\n",
      "torch.Size([2, 12])\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-aa97eb4e3c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-0a850967a2f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNTRY_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-565e6c4bfc5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Embedding S x B -> S x B x I (embedding size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" input size: {input.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Make new tensor because of `EmbeddingGrad`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-565e6c4bfc5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Embedding S x B -> S x B x I (embedding size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" input size: {input.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Make new tensor because of `EmbeddingGrad`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, 1 + 1)):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch, criterion)\n",
    "    test(model, DEVICE, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
