{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement name classifier\n",
    "1. With `GPU`\n",
    "2. With `data parallel`\n",
    "3. Use `pad-pack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from utils import *\n",
    "\n",
    "torch.manual_seed(1249583)\n",
    "\n",
    "# See the details in `Dataset` section\n",
    "SEQUENCE_LENGTH = 19\n",
    "COUNTRY_LENGTH = 18\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, criterion):\n",
    "    \"\"\"\n",
    "    This function has one line different from the ordinary `train()` function\n",
    "    It has `make_variables()` to convert tuple of names to be a tensor\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = make_var(data)        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        import ipdb; ipdb.set_trace()\n",
    "        tmp = output.view(-1, COUNTRY_LENGTH)\n",
    "        loss = criterion(tmp, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data = make_var(data)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            tmp = output.view(-1, COUNTRY_LENGTH)\n",
    "            \n",
    "            test_loss += criterion(tmp, target).item() # sum up batch loss\n",
    "            pred = tmp.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "            pred_tmp = pred.view(-1)\n",
    "            pred_list = pred_tmp.tolist()\n",
    "            target_list = target.tolist()\n",
    "            \n",
    "            y_test += target_list\n",
    "            y_pred += pred_list\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(confusion_mtx, classes=countries, normalize=True,\n",
    "                          title='Confusion matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[116, 105, 114,  97, 115],\n",
       "        [ 97, 110, 110,   0,   0],\n",
       "        [101, 108,   0,   0,   0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = make_var(['Tiras', 'Ann', 'El'])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = count_non_zero_length(tmp)\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(128, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6439,  0.2169, -0.8762, -1.5254,  0.3906],\n",
       "         [-0.9603,  1.1842, -0.7863,  0.0424,  0.6137],\n",
       "         [-0.2403,  0.8440, -1.5594, -0.3972,  0.6235],\n",
       "         [-0.1685,  1.4149, -0.6990, -0.6131, -0.3523],\n",
       "         [-0.2568,  0.3000,  0.1996, -0.7259,  0.1190]],\n",
       "\n",
       "        [[-0.1685,  1.4149, -0.6990, -0.6131, -0.3523],\n",
       "         [-1.1444,  0.3401,  0.2428,  0.3262, -0.0667],\n",
       "         [-1.1444,  0.3401,  0.2428,  0.3262, -0.0667],\n",
       "         [ 0.2763,  0.8555, -1.6694,  0.0883, -0.4541],\n",
       "         [ 0.2763,  0.8555, -1.6694,  0.0883, -0.4541]],\n",
       "\n",
       "        [[-0.4044,  0.1883,  0.6204,  1.1825, -1.1356],\n",
       "         [ 1.8757, -1.0296,  0.5458, -0.4489,  0.0555],\n",
       "         [ 0.2763,  0.8555, -1.6694,  0.0883, -0.4541],\n",
       "         [ 0.2763,  0.8555, -1.6694,  0.0883, -0.4541],\n",
       "         [ 0.2763,  0.8555, -1.6694,  0.0883, -0.4541]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = emb(tmp)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.6439,  0.2169, -0.8762, -1.5254,  0.3906],\n",
       "        [-0.1685,  1.4149, -0.6990, -0.6131, -0.3523],\n",
       "        [-0.4044,  0.1883,  0.6204,  1.1825, -1.1356],\n",
       "        [-0.9603,  1.1842, -0.7863,  0.0424,  0.6137],\n",
       "        [-1.1444,  0.3401,  0.2428,  0.3262, -0.0667],\n",
       "        [ 1.8757, -1.0296,  0.5458, -0.4489,  0.0555],\n",
       "        [-0.2403,  0.8440, -1.5594, -0.3972,  0.6235],\n",
       "        [-1.1444,  0.3401,  0.2428,  0.3262, -0.0667],\n",
       "        [-0.1685,  1.4149, -0.6990, -0.6131, -0.3523],\n",
       "        [-0.2568,  0.3000,  0.1996, -0.7259,  0.1190]],\n",
       "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([3, 3, 2, 1, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pps_in = torch.nn.utils.rnn.pack_padded_sequence(embedding, batch_first=True, lengths=lengths)\n",
    "pps_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6439,  0.2169, -0.8762, -1.5254,  0.3906],\n",
       "          [-0.9603,  1.1842, -0.7863,  0.0424,  0.6137],\n",
       "          [-0.2403,  0.8440, -1.5594, -0.3972,  0.6235],\n",
       "          [-0.1685,  1.4149, -0.6990, -0.6131, -0.3523],\n",
       "          [-0.2568,  0.3000,  0.1996, -0.7259,  0.1190]],\n",
       " \n",
       "         [[-0.1685,  1.4149, -0.6990, -0.6131, -0.3523],\n",
       "          [-1.1444,  0.3401,  0.2428,  0.3262, -0.0667],\n",
       "          [-1.1444,  0.3401,  0.2428,  0.3262, -0.0667],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.4044,  0.1883,  0.6204,  1.1825, -1.1356],\n",
       "          [ 1.8757, -1.0296,  0.5458, -0.4489,  0.0555],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "        grad_fn=<TransposeBackward0>), tensor([5, 3, 2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pps_out = torch.nn.utils.rnn.pad_packed_sequence(pps_in, batch_first=True)\n",
    "pps_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(5, 18, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps_out_n_size, ht = gru(pps_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.nn.utils.rnn.pad_packed_sequence(pps_out_n_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0398, -0.0322, -0.0324,  0.0610, -0.1467,  0.0311,  0.0448,\n",
       "           -0.0966,  0.0651, -0.0526,  0.0418,  0.1969, -0.1536,  0.0622,\n",
       "            0.1267,  0.0826,  0.0359, -0.0155],\n",
       "          [-0.0782, -0.1359, -0.1038,  0.2108, -0.1943,  0.0844,  0.0511,\n",
       "           -0.1212,  0.0822, -0.1003,  0.0061,  0.2858, -0.1862,  0.0660,\n",
       "            0.1276,  0.1697,  0.0536, -0.0362],\n",
       "          [-0.1033, -0.1874, -0.1538,  0.3281, -0.2124,  0.1250,  0.0410,\n",
       "           -0.1497,  0.0773, -0.1291, -0.0145,  0.3420, -0.1857,  0.0656,\n",
       "            0.1044,  0.2455,  0.0378, -0.0688],\n",
       "          [-0.1629, -0.1956, -0.1837,  0.3789, -0.2141,  0.1141,  0.0493,\n",
       "           -0.1904,  0.0883, -0.1211,  0.0082,  0.3449, -0.2034,  0.0834,\n",
       "            0.0911,  0.3039,  0.0361, -0.0964],\n",
       "          [-0.1970, -0.1027, -0.1533,  0.3665, -0.2631,  0.0814,  0.0782,\n",
       "           -0.1954,  0.0884, -0.1026,  0.0082,  0.3306, -0.2201,  0.1205,\n",
       "            0.1267,  0.3046,  0.0361, -0.0902]],\n",
       " \n",
       "         [[-0.0759, -0.1262, -0.0952,  0.1011, -0.1053,  0.0361,  0.0429,\n",
       "           -0.0759,  0.0859, -0.0508,  0.0464,  0.1688, -0.1402,  0.0508,\n",
       "            0.0747,  0.1199,  0.0583, -0.0331],\n",
       "          [-0.1097, -0.1412, -0.1271,  0.1979, -0.1973,  0.0439,  0.0669,\n",
       "           -0.0855,  0.1108, -0.0740,  0.0098,  0.2361, -0.1684,  0.0800,\n",
       "            0.1084,  0.1815,  0.0819, -0.0564],\n",
       "          [-0.1230, -0.1167, -0.1344,  0.2661, -0.2661,  0.0390,  0.0771,\n",
       "           -0.0750,  0.1195, -0.0852, -0.0377,  0.2578, -0.1701,  0.0939,\n",
       "            0.1262,  0.2198,  0.0991, -0.0747],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.0628, -0.0485, -0.0807,  0.0183, -0.1227, -0.0065,  0.0464,\n",
       "           -0.0156,  0.0970, -0.0158,  0.0472,  0.1511, -0.1036,  0.0513,\n",
       "            0.1294,  0.0807,  0.1010, -0.0382],\n",
       "          [-0.1110,  0.1316, -0.0353, -0.0545, -0.1947, -0.0149,  0.0553,\n",
       "           -0.0429,  0.0948, -0.0097,  0.1028,  0.2756, -0.1669,  0.0871,\n",
       "            0.2538,  0.0560,  0.1298, -0.0040],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<TransposeBackward0>),\n",
       " tensor([5, 3, 2]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelX(nn.Module):\n",
    "    def __init__(self, input_size=256, hidden_size=5, output_size=18, n_layers=1):\n",
    "        \"\"\"\n",
    "        Because word embedding is working with ascii. It has to use `input_size=128, hidden_size=256`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # input_size 256, hidden_size 256.\n",
    "        # https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html\n",
    "        self.embedding = nn.Embedding(128, hidden_size) # embedding_dim MUST matches with GRU's input_size \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "        # Decoder layer to tune up the `output` dimension\n",
    "        # TODO\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Do not remove `print`. Leave it be a historical footprint for I myself in the future\n",
    "        \"\"\"\n",
    "        # input = B x S . size(0) = B\n",
    "        batch_size = input.size(0)\n",
    "        lengths = count_non_zero_length(input)\n",
    "        \n",
    "        # Embedding S x B -> S x B x I (embedding size)\n",
    "        print(f\" input size: {input.size()}\")\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = embedded.clone().detach() # Make new tensor because of `EmbeddingGrad`\n",
    "        print(f\" embeddding size: {embedded.size()}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Make a hidden\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        \n",
    "        pps_in = torch.nn.utils.rnn.pack_padded_sequence(embedded, batch_first=True, lengths=lengths)\n",
    "        packed_output, hidden = self.gru(pps_in, hidden)\n",
    "        print(f\" gru hidden output: {hidden.size()}\")\n",
    "        \n",
    "        result, pps_out_size = torch.nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # Use last layer output as FC's input\n",
    "        # No need to unpack, since we are going to use hidden\n",
    "        fc_output = self.fc(result)\n",
    "        print(f\" fc output: {fc_output.size()}\")\n",
    "        import ipdb; ipdb.set_trace()\n",
    "        return fc_output\n",
    "        \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        USE_CUDA = torch.cuda.is_available()\n",
    "        DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "        return hidden.clone().detach().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input size: torch.Size([1, 6])\n",
      " embeddding size: torch.Size([1, 6, 5])\n",
      " gru hidden output: torch.Size([1, 1, 5])\n",
      " fc output: torch.Size([1, 6, 18])\n",
      "> \u001b[0;32m<ipython-input-58-b2aa8ba28e34>\u001b[0m(46)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     45 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 46 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mfc_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     47 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> fc_output\n",
      "tensor([[[-0.2341, -0.1585,  0.3301,  0.4763, -0.4598,  0.4107,  0.3497,\n",
      "           0.0203,  0.2602,  0.2620,  0.1860, -0.1730,  0.1561, -0.3810,\n",
      "           0.2841, -0.1522,  0.0272,  0.1510],\n",
      "         [-0.3585, -0.2016,  0.4147,  0.2924, -0.5790,  0.3416,  0.4077,\n",
      "          -0.0244,  0.5812,  0.2951,  0.2578, -0.2083,  0.2215, -0.2899,\n",
      "           0.4685, -0.0249,  0.1650, -0.1136],\n",
      "         [-0.1940, -0.1583,  0.5266,  0.4613, -0.6034,  0.4934,  0.2155,\n",
      "          -0.1170,  0.4561,  0.1073,  0.3171, -0.3177,  0.3538, -0.3038,\n",
      "           0.4247, -0.1538,  0.0083,  0.0648],\n",
      "         [-0.1739, -0.2247,  0.3342,  0.7122, -0.4454,  0.6400,  0.1685,\n",
      "          -0.2291,  0.0818,  0.0338,  0.0665, -0.2799,  0.2043, -0.3659,\n",
      "           0.1468, -0.3578, -0.2274,  0.2927],\n",
      "         [-0.1567, -0.1769,  0.5020,  0.5910, -0.5729,  0.5838,  0.1235,\n",
      "          -0.1971,  0.3481,  0.0221,  0.2588, -0.3435,  0.3521, -0.3247,\n",
      "           0.3439, -0.2494, -0.1072,  0.1382],\n",
      "         [-0.4436, -0.3984,  0.3707,  0.3539, -0.3972,  0.4074,  0.3973,\n",
      "          -0.2270,  0.4731,  0.2234,  0.1531, -0.1152,  0.2161, -0.1953,\n",
      "           0.3836, -0.2003,  0.0632, -0.1536]]], grad_fn=<AddBackward0>)\n",
      "ipdb> fc_output.size()\n",
      "torch.Size([1, 6, 18])\n",
      "ipdb> fc_output.view(-1, 18)\n",
      "tensor([[-0.2341, -0.1585,  0.3301,  0.4763, -0.4598,  0.4107,  0.3497,  0.0203,\n",
      "          0.2602,  0.2620,  0.1860, -0.1730,  0.1561, -0.3810,  0.2841, -0.1522,\n",
      "          0.0272,  0.1510],\n",
      "        [-0.3585, -0.2016,  0.4147,  0.2924, -0.5790,  0.3416,  0.4077, -0.0244,\n",
      "          0.5812,  0.2951,  0.2578, -0.2083,  0.2215, -0.2899,  0.4685, -0.0249,\n",
      "          0.1650, -0.1136],\n",
      "        [-0.1940, -0.1583,  0.5266,  0.4613, -0.6034,  0.4934,  0.2155, -0.1170,\n",
      "          0.4561,  0.1073,  0.3171, -0.3177,  0.3538, -0.3038,  0.4247, -0.1538,\n",
      "          0.0083,  0.0648],\n",
      "        [-0.1739, -0.2247,  0.3342,  0.7122, -0.4454,  0.6400,  0.1685, -0.2291,\n",
      "          0.0818,  0.0338,  0.0665, -0.2799,  0.2043, -0.3659,  0.1468, -0.3578,\n",
      "         -0.2274,  0.2927],\n",
      "        [-0.1567, -0.1769,  0.5020,  0.5910, -0.5729,  0.5838,  0.1235, -0.1971,\n",
      "          0.3481,  0.0221,  0.2588, -0.3435,  0.3521, -0.3247,  0.3439, -0.2494,\n",
      "         -0.1072,  0.1382],\n",
      "        [-0.4436, -0.3984,  0.3707,  0.3539, -0.3972,  0.4074,  0.3973, -0.2270,\n",
      "          0.4731,  0.2234,  0.1531, -0.1152,  0.2161, -0.1953,  0.3836, -0.2003,\n",
      "          0.0632, -0.1536]], grad_fn=<ViewBackward>)\n",
      "ipdb> tt = fc_output.view(-1, 18)\n",
      "ipdb> tt.size()\n",
      "torch.Size([6, 18])\n",
      "ipdb> tt.t()\n",
      "tensor([[-0.2341, -0.3585, -0.1940, -0.1739, -0.1567, -0.4436],\n",
      "        [-0.1585, -0.2016, -0.1583, -0.2247, -0.1769, -0.3984],\n",
      "        [ 0.3301,  0.4147,  0.5266,  0.3342,  0.5020,  0.3707],\n",
      "        [ 0.4763,  0.2924,  0.4613,  0.7122,  0.5910,  0.3539],\n",
      "        [-0.4598, -0.5790, -0.6034, -0.4454, -0.5729, -0.3972],\n",
      "        [ 0.4107,  0.3416,  0.4934,  0.6400,  0.5838,  0.4074],\n",
      "        [ 0.3497,  0.4077,  0.2155,  0.1685,  0.1235,  0.3973],\n",
      "        [ 0.0203, -0.0244, -0.1170, -0.2291, -0.1971, -0.2270],\n",
      "        [ 0.2602,  0.5812,  0.4561,  0.0818,  0.3481,  0.4731],\n",
      "        [ 0.2620,  0.2951,  0.1073,  0.0338,  0.0221,  0.2234],\n",
      "        [ 0.1860,  0.2578,  0.3171,  0.0665,  0.2588,  0.1531],\n",
      "        [-0.1730, -0.2083, -0.3177, -0.2799, -0.3435, -0.1152],\n",
      "        [ 0.1561,  0.2215,  0.3538,  0.2043,  0.3521,  0.2161],\n",
      "        [-0.3810, -0.2899, -0.3038, -0.3659, -0.3247, -0.1953],\n",
      "        [ 0.2841,  0.4685,  0.4247,  0.1468,  0.3439,  0.3836],\n",
      "        [-0.1522, -0.0249, -0.1538, -0.3578, -0.2494, -0.2003],\n",
      "        [ 0.0272,  0.1650,  0.0083, -0.2274, -0.1072,  0.0632],\n",
      "        [ 0.1510, -0.1136,  0.0648,  0.2927,  0.1382, -0.1536]],\n",
      "       grad_fn=<TBackward>)\n",
      "ipdb> ttt = tt.t()\n",
      "ipdb> ttt\n",
      "tensor([[-0.2341, -0.3585, -0.1940, -0.1739, -0.1567, -0.4436],\n",
      "        [-0.1585, -0.2016, -0.1583, -0.2247, -0.1769, -0.3984],\n",
      "        [ 0.3301,  0.4147,  0.5266,  0.3342,  0.5020,  0.3707],\n",
      "        [ 0.4763,  0.2924,  0.4613,  0.7122,  0.5910,  0.3539],\n",
      "        [-0.4598, -0.5790, -0.6034, -0.4454, -0.5729, -0.3972],\n",
      "        [ 0.4107,  0.3416,  0.4934,  0.6400,  0.5838,  0.4074],\n",
      "        [ 0.3497,  0.4077,  0.2155,  0.1685,  0.1235,  0.3973],\n",
      "        [ 0.0203, -0.0244, -0.1170, -0.2291, -0.1971, -0.2270],\n",
      "        [ 0.2602,  0.5812,  0.4561,  0.0818,  0.3481,  0.4731],\n",
      "        [ 0.2620,  0.2951,  0.1073,  0.0338,  0.0221,  0.2234],\n",
      "        [ 0.1860,  0.2578,  0.3171,  0.0665,  0.2588,  0.1531],\n",
      "        [-0.1730, -0.2083, -0.3177, -0.2799, -0.3435, -0.1152],\n",
      "        [ 0.1561,  0.2215,  0.3538,  0.2043,  0.3521,  0.2161],\n",
      "        [-0.3810, -0.2899, -0.3038, -0.3659, -0.3247, -0.1953],\n",
      "        [ 0.2841,  0.4685,  0.4247,  0.1468,  0.3439,  0.3836],\n",
      "        [-0.1522, -0.0249, -0.1538, -0.3578, -0.2494, -0.2003],\n",
      "        [ 0.0272,  0.1650,  0.0083, -0.2274, -0.1072,  0.0632],\n",
      "        [ 0.1510, -0.1136,  0.0648,  0.2927,  0.1382, -0.1536]],\n",
      "       grad_fn=<TBackward>)\n",
      "ipdb> ttt.size()\n",
      "torch.Size([18, 6])\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-f473c0b1de6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr2ascii_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adylov'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nin: {inp.size()}, \\nout: {out.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-b2aa8ba28e34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" fc output: {fc_output.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfc_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-b2aa8ba28e34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" fc output: {fc_output.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfc_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# classifier = RNNClassifier()\n",
    "classifier = ModelX()\n",
    "arr, _ = str2ascii_arr('adylov')\n",
    "inp = torch.tensor([arr], dtype=torch.long)\n",
    "out = classifier(inp)\n",
    "print(f\"\\nin: {inp.size()}, \\nout: {out.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 18])\n",
      "tensor([[ 0.2650,  0.1078,  0.4122, -0.4748, -0.2397, -0.0794,  0.4312, -0.0862,\n",
      "          0.2040,  0.0309,  0.2786, -0.0256, -0.2849,  0.3879,  0.4688, -0.2300,\n",
      "          0.3165,  0.3080],\n",
      "        [ 0.2847,  0.1856,  0.6050, -0.5111, -0.1214, -0.1743,  0.5501, -0.1887,\n",
      "          0.2534, -0.1171,  0.4144,  0.0651, -0.3758,  0.4415,  0.5154, -0.2968,\n",
      "          0.1395,  0.3997],\n",
      "        [ 0.2395,  0.1942,  0.5395, -0.2764, -0.3767, -0.1780,  0.2264, -0.2316,\n",
      "          0.0061, -0.1115,  0.1503,  0.0484, -0.3791,  0.3653,  0.5168, -0.0732,\n",
      "          0.2596,  0.3354],\n",
      "        [ 0.3090,  0.1471,  0.4178, -0.2902, -0.4253, -0.2231,  0.1582, -0.2118,\n",
      "          0.0295, -0.0431,  0.2183,  0.0966, -0.4682,  0.3416,  0.3960, -0.1166,\n",
      "          0.4257,  0.4236],\n",
      "        [ 0.2306,  0.1888,  0.4193, -0.2122, -0.5594, -0.2429, -0.0150, -0.2258,\n",
      "         -0.0891, -0.0667,  0.0550,  0.0142, -0.4226,  0.2745,  0.3441, -0.0214,\n",
      "          0.4250,  0.3577],\n",
      "        [-0.0126,  0.3229,  0.5359, -0.1768, -0.7059, -0.2473, -0.2209, -0.2486,\n",
      "         -0.2574, -0.1890, -0.2380, -0.2467, -0.2276,  0.1621,  0.2356,  0.1007,\n",
      "          0.2433,  0.1618]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "my_view = out.view(-1, 18)\n",
    "print(my_view.size())\n",
    "print(my_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input size: torch.Size([4, 6])\n",
      " embeddding size: torch.Size([4, 6, 5])\n",
      " gru hidden output: torch.Size([1, 4, 5])\n",
      " fc output: torch.Size([4, 6, 18])\n",
      "\n",
      "batch in: torch.Size([4, 6]), \n",
      "batch out: torch.Size([4, 6, 18])\n"
     ]
    }
   ],
   "source": [
    "names = ['adylov', 'solan', 'hard', 'san']\n",
    "# classifier = RNNClassifier()\n",
    "classifier = ModelX()\n",
    "inputs = make_var(names)\n",
    "out = classifier(inputs)\n",
    "print(f\"\\nbatch in: {inputs.size()}, \\nbatch out: {out.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size=256, hidden_size=256, output_size=18, n_layers=1):\n",
    "        \"\"\"\n",
    "        Because word embedding is working with ascii. It has to use `input_size=128, hidden_size=256`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # input_size 256, hidden_size 256.\n",
    "        # https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html\n",
    "        self.embedding = nn.Embedding(128, hidden_size) # embedding_dim MUST matches with GRU's input_size \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Do not remove `print`. Leave it be a historical footprint for I myself in the future\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sung Kim run this all at once (over the whole input sequence)\n",
    "        # input = B x S . size(0) = B\n",
    "        batch_size = input.size(0)\n",
    "        \n",
    "        # input: B x S -- (transpose) --> S x B\n",
    "        input = input.t()\n",
    "        \n",
    "        # Embedding S x B -> S x B x I (embedding size)\n",
    "        print(f\" input size: {input.size()}\")\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = embedded.clone().detach() # Make new tensor because of `EmbeddingGrad`\n",
    "        print(f\" embeddding size: {embedded.size()}\")\n",
    "        \n",
    "        # Make a hidden\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        print(f\" gru hidden output: {hidden.size()}\")\n",
    "        \n",
    "        # Use last layer output as FC's input\n",
    "        # No need to unpack, since we are going to use hidden\n",
    "        fc_output = self.fc(hidden)\n",
    "        print(f\" fc output: {fc_output.size()}\")\n",
    "        return fc_output\n",
    "        \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        USE_CUDA = torch.cuda.is_available()\n",
    "        DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "        return hidden.clone().detach().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataSet(Dataset):\n",
    "    def __init__(self, filename='names_train.csv'):\n",
    "        trainset = pd.read_csv(filename, header=None)\n",
    "        trainset.columns = ['name', 'country']\n",
    "        countries = sorted(list(trainset.country.drop_duplicates()))\n",
    "\n",
    "        self.trainset = trainset\n",
    "        self.countries = countries\n",
    "        self.len = len(trainset)        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        country = self.trainset.iloc[index]['country']\n",
    "        return self.trainset.iloc[index]['name'], self.countries.index(country)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NameDataSet(filename='../lessons/names_train.csv')\n",
    "test_dataset = NameDataSet(filename='../lessons/names_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.79 s, sys: 0 ns, total: 8.79 s\n",
      "Wall time: 8.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loader = DataLoader(dataset=train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=2, num_workers=2) # 2 * 9 * 743 \n",
    "test_loader = DataLoader(dataset=test_dataset, sampler=ImbalancedDatasetSampler(test_dataset), batch_size=2, num_workers=2) # 4 * 25 * 67\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNNClassifier().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelX().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Criterion & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf27e880b3404a82a644bb6fe88d2882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input size: torch.Size([2, 5])\n",
      " embeddding size: torch.Size([2, 5, 5])\n",
      " gru hidden output: torch.Size([1, 2, 5])\n",
      " fc output: torch.Size([2, 5, 18])\n",
      "> \u001b[0;32m<ipython-input-42-74fa70e5fbdc>\u001b[0m(18)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     17 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m        \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNTRY_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> output\n",
      "tensor([[[ 3.1571e-01,  4.3976e-04,  2.6814e-02,  2.3949e-01,  5.0734e-01,\n",
      "          -3.2914e-01, -1.1811e-01, -5.1694e-01,  3.0503e-01, -2.9958e-01,\n",
      "           2.1942e-01, -2.6824e-01,  3.7333e-01,  5.2506e-01, -2.1306e-01,\n",
      "           1.3651e-02, -5.8526e-01, -7.9034e-02],\n",
      "         [ 5.6820e-01,  1.3844e-01, -1.6431e-01,  2.8195e-01,  3.5517e-01,\n",
      "          -3.0841e-01, -4.7572e-02, -5.8680e-01,  2.5179e-01, -4.7138e-01,\n",
      "           5.1120e-01, -1.3851e-01,  1.9107e-01,  6.5842e-01, -1.0666e-01,\n",
      "           2.3999e-01, -4.4572e-01, -5.1674e-02],\n",
      "         [ 4.4594e-01, -5.9803e-02,  6.5626e-02,  2.0313e-01,  3.5801e-01,\n",
      "          -6.0184e-01, -1.3729e-03, -5.7446e-01,  3.5641e-01, -6.1430e-02,\n",
      "           9.9902e-02, -7.3963e-02,  2.4677e-01,  6.5170e-01,  1.2405e-01,\n",
      "           6.5148e-02, -6.3823e-01, -2.8650e-01],\n",
      "         [ 2.5127e-01, -2.3961e-01,  1.5235e-01,  1.1422e-01,  3.9331e-01,\n",
      "          -5.7309e-01, -2.8995e-02, -4.7174e-01,  3.6880e-01,  7.6761e-02,\n",
      "          -1.5039e-01, -9.2296e-02,  2.9946e-01,  4.9907e-01,  8.4024e-02,\n",
      "          -4.0116e-02, -6.6497e-01, -3.0823e-01],\n",
      "         [ 8.7925e-02, -4.4617e-01,  1.4159e-01,  3.3698e-02,  3.8868e-01,\n",
      "          -4.9380e-01, -2.3900e-02, -3.4959e-01,  3.4641e-01,  1.0829e-01,\n",
      "          -3.1906e-01, -3.7892e-02,  2.4486e-01,  3.0230e-01,  4.4307e-02,\n",
      "          -9.1416e-02, -5.9473e-01, -2.8099e-01]],\n",
      "\n",
      "        [[ 3.1616e-01, -7.2580e-02, -4.6729e-02,  1.5449e-01,  3.8555e-01,\n",
      "          -3.7845e-01, -1.2092e-01, -4.3280e-01,  2.8466e-01, -1.7112e-01,\n",
      "           1.2276e-01, -1.4142e-01,  2.0050e-01,  4.8019e-01, -9.0316e-02,\n",
      "           9.0784e-02, -5.3784e-01, -1.0351e-01],\n",
      "         [ 2.5544e-01, -1.5021e-01,  9.8921e-02,  2.5959e-01,  5.4158e-01,\n",
      "          -5.1936e-01, -4.5429e-02, -5.1807e-01,  3.5679e-01, -1.8684e-01,\n",
      "           5.8624e-02, -1.6797e-01,  3.1138e-01,  4.6759e-01, -8.4602e-02,\n",
      "          -1.2542e-01, -6.4534e-01, -1.6826e-01],\n",
      "         [ 3.0164e-03, -2.1965e-01,  9.5039e-02,  9.9172e-02,  5.7211e-01,\n",
      "          -1.5499e-01, -2.1897e-01, -3.2367e-01,  2.8470e-01, -1.8585e-01,\n",
      "          -7.9957e-02, -3.5300e-01,  4.5722e-01,  2.5779e-01, -3.9314e-01,\n",
      "          -1.0217e-01, -5.7385e-01, -1.5319e-02],\n",
      "         [ 2.2087e-01, -3.1061e-01, -7.9139e-02,  1.6757e-01,  4.2000e-01,\n",
      "          -2.3188e-01,  1.1640e-02, -4.0556e-01,  2.5422e-01, -3.8845e-01,\n",
      "           1.2456e-01, -5.4032e-02,  1.7889e-01,  2.8843e-01, -1.6522e-01,\n",
      "           2.9290e-02, -3.7956e-01, -6.2869e-02],\n",
      "         [ 2.2087e-01, -3.1061e-01, -7.9139e-02,  1.6757e-01,  4.2000e-01,\n",
      "          -2.3188e-01,  1.1640e-02, -4.0556e-01,  2.5422e-01, -3.8845e-01,\n",
      "           1.2456e-01, -5.4032e-02,  1.7889e-01,  2.8843e-01, -1.6522e-01,\n",
      "           2.9290e-02, -3.7956e-01, -6.2869e-02]]], grad_fn=<AddBackward0>)\n",
      "ipdb> output.size()\n",
      "torch.Size([2, 5, 18])\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-42-74fa70e5fbdc>\u001b[0m(19)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     18 \u001b[0;31m        \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNTRY_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m        \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> tmp.size()\n",
      "torch.Size([10, 18])\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-aa97eb4e3c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-74fa70e5fbdc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNTRY_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-74fa70e5fbdc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNTRY_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, 1 + 1)):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch, criterion)\n",
    "    test(model, DEVICE, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
