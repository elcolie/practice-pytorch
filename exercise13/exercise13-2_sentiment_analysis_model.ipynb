{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import RawDataset, ImbalancedDatasetSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "SEQUENCE_LENGTH = 56 # Analysis file at `maximum input_size`\n",
    "SENTIMENT_CLASSES = 5 \n",
    "CLASSES = ['negative', 'somewhat neg', 'neutral', 'somewhat pos', 'positive']\n",
    "EMBEDDING_SIZE = 19479 # len(my_dict.idx2word)\n",
    "\n",
    "torch.manual_seed(1111111)\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['PhraseId', 'SentenceId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31212.0, 7803.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)/4, len(test)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phrase       what is good for the goose\n",
       "Sentiment                             2\n",
       "Name: 17, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RawDataset(train)\n",
    "test_dataset = RawDataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Found bug when using ImbalancedDatasetSampler\n",
    "DataLoader will randomly return me arbitrary `batch_size`. Therefore I have to use `batch_size=1` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 90 ms, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loader = DataLoader(dataset=train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=4, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_dataset, sampler=ImbalancedDatasetSampler(test_dataset), batch_size=4, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('train_loader.pkl', 'rb') as my_input:\n",
    "    train_loader = pickle.load(my_input)\n",
    "with open('test_loader.pkl', 'rb') as my_input2:\n",
    "    test_loader = pickle.load(my_input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "with open('train_loader.pkl', 'wb') as output:\n",
    "    pickle.dump(train_loader, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open('test_loader.pkl', 'wb') as output:\n",
    "    pickle.dump(test_loader, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i, (data, target) in enumerate(train_loader):\n",
    "    if i == 0:\n",
    "        import ipdb; ipdb.set_trace()\n",
    "        print(data)\n",
    "        print(target)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, criterion):\n",
    "    \"\"\"\n",
    "    This function has one line different from the ordinary `train()` function\n",
    "    It has `make_variables()` to convert tuple of names to be a tensor\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        # For some reason `train_loader` encapsulates my data with tuple\n",
    "        local_dummy = [i.lower().split(' ') for i in data]\n",
    "        inputs = make_variables(local_dummy)\n",
    "\n",
    "        data, target = inputs.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        tmp = output.view(-1, SENTIMENT_CLASSES)\n",
    "        \n",
    "        loss = criterion(tmp, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            local_dummy = [i.lower().split(' ') for i in data]\n",
    "            inputs = make_variables(local_dummy)\n",
    "            \n",
    "            data, target = inputs.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            tmp = output.view(-1, SENTIMENT_CLASSES)\n",
    "\n",
    "            test_loss += criterion(tmp, target).item() # sum up batch loss\n",
    "            pred = tmp.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "            pred_tmp = pred.view(-1)\n",
    "            pred_list = pred_tmp.tolist()\n",
    "            target_list = target.tolist()\n",
    "            \n",
    "            y_test += target_list\n",
    "            y_pred += pred_list\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(confusion_mtx, classes=CLASSES, normalize=True,\n",
    "                          title='Confusion matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size=56, hidden_size=256, output_size=5, n_layers=1, num_embedding=19500, embedding_dim=300):\n",
    "        \"\"\"\n",
    "        Because word embedding is working with ascii. It has to use `input_size=256, hidden_size=256`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # input_size 256, hidden_size 256.\n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Do not remove `print`. Leave it be a historical footprint for I myself in the future\n",
    "        \"\"\"\n",
    "        # Sung Kim run this all at once (over the whole input sequence)\n",
    "        # input = B x S . size(0) = B\n",
    "        batch_size = input.size(0)\n",
    "        \n",
    "        # input: B x S -- (transpose) --> S x B\n",
    "        input = input.t()\n",
    "        \n",
    "        # Embedding S x B -> S x B x I (embedding size)\n",
    "        # print(f\" input size: {input.size()}\")\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = embedded.clone().detach() # Make new tensor because of `EmbeddingGrad`\n",
    "        # print(f\" embeddding size: {embedded.size()}\")\n",
    "        \n",
    "        # Make a hidden\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        # print(f\" gru hidden output: {hidden.size()}\")\n",
    "        \n",
    "        # Use last layer output as FC's input\n",
    "        # No need to unpack, since we are going to use hidden\n",
    "        fc_output = self.fc(hidden)\n",
    "        # print(f\" fc output: {fc_output.size()}\")\n",
    "        return fc_output\n",
    "        \n",
    "    def _init_hidden(self, batch_size):\n",
    "        USE_CUDA = torch.cuda.is_available()\n",
    "        DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        return hidden.clone().detach().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils import Dictionary\n",
    "\n",
    "with open('dictioanry_data.pkl', 'rb') as input:\n",
    "    my_dict = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of `inputs`\n",
    "data is a `batch` from `DataLoader`. And `inputs` is a tensor of dictionary index.<br>\n",
    "After that `model` supposed to handle `indexes` by embedded layer and calculate on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2word_idx_arr(tokenized_sentence):\n",
    "    \"\"\"\n",
    "    string to word-index and array\n",
    "    \"\"\"\n",
    "    arr = [my_dict.word2idx[word] for word in tokenized_sentence]\n",
    "    return arr, len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(vectorized_seqs, seq_lengths):\n",
    "    \"\"\"\n",
    "    Let the `SEQUENCE_LENGTH` is 19. According to the dataset\n",
    "    \"\"\"\n",
    "    seq_tensor = torch.zeros((len(vectorized_seqs), SEQUENCE_LENGTH), dtype=torch.long)\n",
    "    for idx, (seq, seq_len) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "        seq_tensor[idx, :seq_len] = torch.tensor(seq, dtype=torch.long)\n",
    "    return seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  41, 1828, 2336,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   8,    9,   10,   11,    5,   12,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_variables(sentence):\n",
    "    sequence_and_length = [str2word_idx_arr(word) for word in sentence]\n",
    "    vectorized_seqs = [sl[0] for sl in sequence_and_length]\n",
    "    seq_lengths = torch.tensor([sl[1] for sl in sequence_and_length])\n",
    "    return pad_sequences(vectorized_seqs, seq_lengths)\n",
    "\n",
    "make_variables(['i my cat'.split(' '), 'what is good for the goose'.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNClassifier(input_size=56).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['with', 'melancholy', 'richness'],\n",
      " ['looks', 'more', 'like', 'danny', 'aiello'],\n",
      " ['circumstances'],\n",
      " ['the', 'dead']]\n",
      "tensor([[   94,  3131,  4113,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [ 1935,   216,    98, 10820, 15578,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [ 1046,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [    5,  2254,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 4\n",
    "from pprint import pprint\n",
    "data = (\n",
    "    'with melancholy richness',\n",
    "    'looks more like Danny Aiello',\n",
    "    'circumstances',\n",
    "    'the dead',\n",
    ")\n",
    "local_dummy = [i.lower().split(' ') for i in data]\n",
    "inputs = make_variables(local_dummy)\n",
    "pprint(local_dummy)\n",
    "pprint(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1084,  0.1726, -0.1765, -0.2090,  0.0809],\n",
       "         [ 0.1084,  0.1725, -0.1764, -0.2092,  0.0809],\n",
       "         [ 0.1084,  0.1727, -0.1766, -0.2090,  0.0809],\n",
       "         [ 0.1084,  0.1726, -0.1766, -0.2090,  0.0809]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs.to(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Criterion & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19479"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(my_dict.idx2word) #19479\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNClassifier(input_size=input_size).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998a8c38d7924b06a98aa68925d51d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31212), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/124848 (0%)]\tLoss: 1.819080\n",
      "Train Epoch: 1 [4000/124848 (3%)]\tLoss: 1.654910\n",
      "Train Epoch: 1 [8000/124848 (6%)]\tLoss: 1.580096\n",
      "Train Epoch: 1 [12000/124848 (10%)]\tLoss: 1.527628\n",
      "Train Epoch: 1 [16000/124848 (13%)]\tLoss: 1.144054\n",
      "Train Epoch: 1 [20000/124848 (16%)]\tLoss: 1.414001\n",
      "Train Epoch: 1 [24000/124848 (19%)]\tLoss: 1.431541\n",
      "Train Epoch: 1 [28000/124848 (22%)]\tLoss: 1.437923\n",
      "Train Epoch: 1 [32000/124848 (26%)]\tLoss: 1.853313\n",
      "Train Epoch: 1 [36000/124848 (29%)]\tLoss: 1.022406\n",
      "Train Epoch: 1 [40000/124848 (32%)]\tLoss: 0.997144\n",
      "Train Epoch: 1 [44000/124848 (35%)]\tLoss: 1.366148\n",
      "Train Epoch: 1 [48000/124848 (38%)]\tLoss: 1.423986\n",
      "Train Epoch: 1 [52000/124848 (42%)]\tLoss: 1.003134\n",
      "Train Epoch: 1 [56000/124848 (45%)]\tLoss: 0.994516\n",
      "Train Epoch: 1 [60000/124848 (48%)]\tLoss: 1.093737\n",
      "Train Epoch: 1 [64000/124848 (51%)]\tLoss: 1.319923\n",
      "Train Epoch: 1 [68000/124848 (54%)]\tLoss: 1.581661\n",
      "Train Epoch: 1 [72000/124848 (58%)]\tLoss: 1.124301\n",
      "Train Epoch: 1 [76000/124848 (61%)]\tLoss: 0.651068\n",
      "Train Epoch: 1 [80000/124848 (64%)]\tLoss: 0.976553\n",
      "Train Epoch: 1 [84000/124848 (67%)]\tLoss: 1.512149\n",
      "Train Epoch: 1 [88000/124848 (70%)]\tLoss: 0.930616\n",
      "Train Epoch: 1 [92000/124848 (74%)]\tLoss: 0.829231\n",
      "Train Epoch: 1 [96000/124848 (77%)]\tLoss: 0.602853\n",
      "Train Epoch: 1 [100000/124848 (80%)]\tLoss: 0.672229\n",
      "Train Epoch: 1 [104000/124848 (83%)]\tLoss: 0.568980\n",
      "Train Epoch: 1 [108000/124848 (87%)]\tLoss: 1.496195\n",
      "Train Epoch: 1 [112000/124848 (90%)]\tLoss: 0.992727\n",
      "Train Epoch: 1 [116000/124848 (93%)]\tLoss: 1.297593\n",
      "Train Epoch: 1 [120000/124848 (96%)]\tLoss: 0.924747\n",
      "Train Epoch: 1 [124000/124848 (99%)]\tLoss: 0.786621\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19da716600bc471eb3b8f2b7691a1153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7803), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(1, 1 + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch, criterion)\n",
    "    test(model, DEVICE, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(model, 'sentiment-classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = [torch.tensor([1,2,3]), torch.tensor([3,4])]\n",
    "b = torch.nn.utils.rnn.pad_sequence(a, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3]), tensor([3, 4])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1, 3, 2, 4, 3]), batch_sizes=tensor([2, 2, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pack_padded_sequence(b, batch_first=True, lengths=[3,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
