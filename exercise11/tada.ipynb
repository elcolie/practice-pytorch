{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5lJvnOoIMI6-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.cuda.manual_seed(151515151)\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5KXM2MXZZgbQ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8q1H4GJnNsO_",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train, )\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True, **kwargs)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False, **kwargs)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Q8lr-gWOOAym",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            y_test += list(target)\n",
    "            y_pred += list(pred.view_as(target))\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(confusion_mtx, classes=classes, normalize=True,\n",
    "                          title='Confusion matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rpSVmSGUODKC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class InceptionA(nn.Module):\n",
    "    def __init__(self, in_channels=384, out_channels=1024):\n",
    "        super().__init__()\n",
    "        self.conv1x1_96 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        \n",
    "        self.conv1x1_64_l2 = nn.Conv2d(in_channels, 64, kernel_size=1, stride=1)\n",
    "        self.conv3x3_96 = nn.Conv2d(64, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv1x1_64_l3 = nn.Conv2d(in_channels, 64, kernel_size=1, stride=1)\n",
    "        self.conv3x3_96_l3 = nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3x3_96_l3_last = nn.Conv2d(96, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        \n",
    "        self.rrelu = nn.LeakyReLU()        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x0 = self.rrelu(self.conv1x1_96(x))\n",
    "\n",
    "        x1 = self.rrelu(self.conv1x1_64_l2(x))\n",
    "        x1 = self.rrelu(self.conv3x3_96(x1))\n",
    "        \n",
    "        x2 = self.rrelu(self.conv1x1_64_l3(x))\n",
    "        x2 = self.rrelu(self.conv3x3_96_l3(x2))\n",
    "        x2 = self.rrelu(self.conv3x3_96_l3_last(x2))\n",
    "        \n",
    "        x3 = self.rrelu(self.avg_pool(x))\n",
    "        x3 = self.rrelu(self.conv1x1(x3))\n",
    "\n",
    "        outputs = [x0, x1, x2, x3]\n",
    "        return torch.cat(outputs, 1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Mf_7vJJVOGg0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class ReductionA(nn.Module):\n",
    "    def __init__(self, in_channels=384, out_channels=1024):\n",
    "        super().__init__()\n",
    "        self.max_pool = nn.MaxPool2d(3, stride=2)\n",
    "        \n",
    "        self.conv3x3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2)\n",
    "        \n",
    "        self.conv1x1_2 = nn.Conv2d(in_channels, 192, kernel_size=1, stride=1)\n",
    "        self.conv3x3_2 = nn.Conv2d(192, 224, kernel_size=3, stride=1 , padding=1)\n",
    "        self.conv3x3_last = nn.Conv2d(224, out_channels, kernel_size=3, stride=2)\n",
    "        \n",
    "        self.rrelu = nn.LeakyReLU()\n",
    "    def forward(self, x):\n",
    "        x0 = self.rrelu(self.conv3x3_1(x))\n",
    "        x1 = self.rrelu(self.conv1x1_2(x))\n",
    "        x1 = self.rrelu(self.conv3x3_2(x1))\n",
    "        x1 = self.rrelu(self.conv3x3_last(x1))\n",
    "        x2 = self.rrelu(self.max_pool(x))\n",
    "        outputs = [x0, x1, x2]\n",
    "        return torch.cat(outputs, 1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3kIVXIeeOIC8",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"Experiment relu and linear layer with as is stem\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inception_a = InceptionA(in_channels=3)\n",
    "        self.reduction_a = ReductionA(in_channels=4096, out_channels=384)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.rrelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc_last = nn.Linear(43776, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        \n",
    "        x = self.rrelu(self.mp(self.inception_a(x)))\n",
    "        x = self.rrelu(self.mp(self.reduction_a(x)))\n",
    "        \n",
    "        x = x.view(in_size, -1) # flatten the tensor\n",
    "        \n",
    "        x = F.rrelu(self.fc_last(x))\n",
    "        x = self.dropout(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "46F4pnbGowZA",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "lYoqwe6JaJUa",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "U-kk896oOJgq",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "model = model.cuda()\n",
    "model.apply(init_weights)\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-DADLrpmOK2t",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Sobu-WxxOMFO",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, 1 + 1):\n",
    "    train(model, 'cuda', trainloader, optimizer, epoch)\n",
    "    test(model, 'cuda', testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "WgKMD-TKOM-D",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rZ_rp8hVR0TD",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "D4jHO8nmU3M_",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tada.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
