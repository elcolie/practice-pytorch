{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "1. Dataset uses `pandas` not `numpy`\n",
    "1. Data normalization\n",
    "1. Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabeteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        raw_df = pd.read_csv(csv_file)\n",
    "        df = (raw_df - raw_df.mean())/raw_df.std()\n",
    "        \n",
    "        self.len = df.shape[0]\n",
    "\n",
    "        x_columns = list(df.columns)\n",
    "        x_columns.remove('Class')\n",
    "        x_columns\n",
    "        \n",
    "        self.x_data = df[x_columns]\n",
    "        self.y_data = raw_df['Class']\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.x_data.iloc[index], dtype=torch.float32), bool(self.y_data.iloc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI\n",
    "https://github.com/MateLabs/Public-Datasets/blob/master/Datasets/diabetes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampler import ImbalancedDatasetSampler\n",
    "\n",
    "# train_dataset = DiabeteDataset('diabetes_train.csv') # 768 rows\n",
    "\n",
    "train_dataset = DiabeteDataset('diabetes_train.csv')\n",
    "test_dataset = DiabeteDataset('diabetes_test.csv')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=2, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelDeep(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Input layer is (8 , 8)\n",
    "        Hidder layer is (8, 8)\n",
    "        Ouput layser is (8, 1)\n",
    "        3 layers loss is ~5\n",
    "        8 layers loss is ~4\n",
    "        21 layer losss is ~4\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 8)\n",
    "        self.l2 = torch.nn.Linear(8, 8)\n",
    "        self.l3 = torch.nn.Linear(8, 8)\n",
    "        self.l4 = torch.nn.Linear(8, 8)\n",
    "        self.l5 = torch.nn.Linear(8, 8)\n",
    "        self.l6 = torch.nn.Linear(8, 8)\n",
    "        self.l7 = torch.nn.Linear(8, 8)\n",
    "        self.l8 = torch.nn.Linear(8, 8)\n",
    "        self.l9 = torch.nn.Linear(8, 8)\n",
    "        self.l10 = torch.nn.Linear(8, 8)\n",
    "        self.l11 = torch.nn.Linear(8, 8)\n",
    "        self.l12 = torch.nn.Linear(8, 8)\n",
    "        self.l13 = torch.nn.Linear(8, 8)\n",
    "        self.l14 = torch.nn.Linear(8, 8)\n",
    "        self.l15 = torch.nn.Linear(8, 8)\n",
    "        self.l16 = torch.nn.Linear(8, 8)\n",
    "        self.l17 = torch.nn.Linear(8, 8)\n",
    "        self.l18 = torch.nn.Linear(8, 8)\n",
    "        self.l19 = torch.nn.Linear(8, 8)\n",
    "        self.l20 = torch.nn.Linear(8, 8)\n",
    "        self.l21 = torch.nn.Linear(8, 1)\n",
    "    \n",
    "        # Activation function\n",
    "        self.activation_fn = torch.nn.LeakyReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.l1(x))\n",
    "        x = self.activation_fn(self.l2(x))\n",
    "        x = self.activation_fn(self.l3(x))\n",
    "        x = self.activation_fn(self.l4(x))\n",
    "        x = self.activation_fn(self.l5(x))\n",
    "        x = self.activation_fn(self.l6(x))\n",
    "        x = self.activation_fn(self.l7(x))\n",
    "        x = self.activation_fn(self.l8(x))\n",
    "        x = self.activation_fn(self.l9(x))\n",
    "        x = self.activation_fn(self.l10(x))        \n",
    "        x = self.activation_fn(self.l11(x))\n",
    "        x = self.activation_fn(self.l12(x))        \n",
    "        x = self.activation_fn(self.l13(x))\n",
    "        x = self.activation_fn(self.l14(x))\n",
    "        x = self.activation_fn(self.l15(x))\n",
    "        x = self.activation_fn(self.l16(x))        \n",
    "        x = self.activation_fn(self.l17(x))\n",
    "        x = self.activation_fn(self.l18(x))        \n",
    "        x = self.activation_fn(self.l19(x))\n",
    "        x = self.activation_fn(self.l20(x))        \n",
    "        x = self.sigmoid(self.l21(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWide(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 60)\n",
    "        self.l2 = torch.nn.Linear(60, 60)\n",
    "        self.l3 = torch.nn.Linear(60, 60)\n",
    "        self.l4 = torch.nn.Linear(60, 60)\n",
    "        self.l5 = torch.nn.Linear(60, 60)\n",
    "        self.l6 = torch.nn.Linear(60, 60)\n",
    "        self.l7 = torch.nn.Linear(60, 60)\n",
    "        self.l8 = torch.nn.Linear(60, 60)\n",
    "        self.l9 = torch.nn.Linear(60, 60)\n",
    "        self.l10 = torch.nn.Linear(60, 60)\n",
    "        self.l11 = torch.nn.Linear(60, 60)\n",
    "        self.l12 = torch.nn.Linear(60, 60)\n",
    "        self.l13 = torch.nn.Linear(60, 60)\n",
    "        self.l14 = torch.nn.Linear(60, 1)\n",
    "    \n",
    "        # Activation function\n",
    "        self.activation_fn = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.l1(x))\n",
    "        x = self.activation_fn(self.l2(x))\n",
    "        x = self.activation_fn(self.l3(x))\n",
    "        x = self.activation_fn(self.l4(x))\n",
    "        x = self.activation_fn(self.l5(x))\n",
    "        x = self.activation_fn(self.l6(x))\n",
    "        x = self.activation_fn(self.l7(x))\n",
    "        x = self.activation_fn(self.l8(x))\n",
    "        x = self.activation_fn(self.l9(x))\n",
    "        x = self.activation_fn(self.l10(x))        \n",
    "        x = self.activation_fn(self.l11(x))\n",
    "        x = self.activation_fn(self.l12(x))        \n",
    "        x = self.activation_fn(self.l13(x))\n",
    "        x = self.activation_fn(self.l14(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KopxionAkramsystems(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Thin model ~80%\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 32)\n",
    "        self.l2 = torch.nn.Linear(32, 1)\n",
    "        self.activation_fn = torch.nn.LeakyReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.l1(x))\n",
    "        x = self.sigmoid(self.l2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KopxionAkramsystems()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/700 (0%)]\tLoss: 0.997718\n",
      "Train Epoch: 0 [20/700 (3%)]\tLoss: 1.020648\n",
      "Train Epoch: 0 [40/700 (6%)]\tLoss: 0.426839\n",
      "Train Epoch: 0 [60/700 (9%)]\tLoss: 0.752995\n",
      "Train Epoch: 0 [80/700 (11%)]\tLoss: 0.452757\n",
      "Train Epoch: 0 [100/700 (14%)]\tLoss: 0.752967\n",
      "Train Epoch: 0 [120/700 (17%)]\tLoss: 0.717417\n",
      "Train Epoch: 0 [140/700 (20%)]\tLoss: 0.700582\n",
      "Train Epoch: 0 [160/700 (23%)]\tLoss: 0.456189\n",
      "Train Epoch: 0 [180/700 (26%)]\tLoss: 0.709622\n",
      "Train Epoch: 0 [200/700 (29%)]\tLoss: 0.746272\n",
      "Train Epoch: 0 [220/700 (31%)]\tLoss: 0.712057\n",
      "Train Epoch: 0 [240/700 (34%)]\tLoss: 0.433087\n",
      "Train Epoch: 0 [260/700 (37%)]\tLoss: 0.456629\n",
      "Train Epoch: 0 [280/700 (40%)]\tLoss: 0.712492\n",
      "Train Epoch: 0 [300/700 (43%)]\tLoss: 0.455026\n",
      "Train Epoch: 0 [320/700 (46%)]\tLoss: 0.672329\n",
      "Train Epoch: 0 [340/700 (49%)]\tLoss: 0.724226\n",
      "Train Epoch: 0 [360/700 (51%)]\tLoss: 0.668571\n",
      "Train Epoch: 0 [380/700 (54%)]\tLoss: 0.726517\n",
      "Train Epoch: 0 [400/700 (57%)]\tLoss: 0.739626\n",
      "Train Epoch: 0 [420/700 (60%)]\tLoss: 0.464381\n",
      "Train Epoch: 0 [440/700 (63%)]\tLoss: 0.701443\n",
      "Train Epoch: 0 [460/700 (66%)]\tLoss: 0.448256\n",
      "Train Epoch: 0 [480/700 (69%)]\tLoss: 0.945729\n",
      "Train Epoch: 0 [500/700 (71%)]\tLoss: 0.942516\n",
      "Train Epoch: 0 [520/700 (74%)]\tLoss: 0.434959\n",
      "Train Epoch: 0 [540/700 (77%)]\tLoss: 0.687956\n",
      "Train Epoch: 0 [560/700 (80%)]\tLoss: 0.912352\n",
      "Train Epoch: 0 [580/700 (83%)]\tLoss: 0.442064\n",
      "Train Epoch: 0 [600/700 (86%)]\tLoss: 0.820545\n",
      "Train Epoch: 0 [620/700 (89%)]\tLoss: 0.711980\n",
      "Train Epoch: 0 [640/700 (91%)]\tLoss: 0.620081\n",
      "Train Epoch: 0 [660/700 (94%)]\tLoss: 0.628527\n",
      "Train Epoch: 0 [680/700 (97%)]\tLoss: 0.697080\n",
      "Train Epoch: 1 [0/700 (0%)]\tLoss: 0.571350\n",
      "Train Epoch: 1 [20/700 (3%)]\tLoss: 0.650355\n",
      "Train Epoch: 1 [40/700 (6%)]\tLoss: 0.478525\n",
      "Train Epoch: 1 [60/700 (9%)]\tLoss: 0.646551\n",
      "Train Epoch: 1 [80/700 (11%)]\tLoss: 0.633350\n",
      "Train Epoch: 1 [100/700 (14%)]\tLoss: 0.658675\n",
      "Train Epoch: 1 [120/700 (17%)]\tLoss: 0.727285\n",
      "Train Epoch: 1 [140/700 (20%)]\tLoss: 1.055281\n",
      "Train Epoch: 1 [160/700 (23%)]\tLoss: 0.669105\n",
      "Train Epoch: 1 [180/700 (26%)]\tLoss: 0.589879\n",
      "Train Epoch: 1 [200/700 (29%)]\tLoss: 0.491974\n",
      "Train Epoch: 1 [220/700 (31%)]\tLoss: 0.577552\n",
      "Train Epoch: 1 [240/700 (34%)]\tLoss: 0.691197\n",
      "Train Epoch: 1 [260/700 (37%)]\tLoss: 0.805310\n",
      "Train Epoch: 1 [280/700 (40%)]\tLoss: 0.610893\n",
      "Train Epoch: 1 [300/700 (43%)]\tLoss: 0.667029\n",
      "Train Epoch: 1 [320/700 (46%)]\tLoss: 0.812478\n",
      "Train Epoch: 1 [340/700 (49%)]\tLoss: 0.768083\n",
      "Train Epoch: 1 [360/700 (51%)]\tLoss: 0.875175\n",
      "Train Epoch: 1 [380/700 (54%)]\tLoss: 0.764062\n",
      "Train Epoch: 1 [400/700 (57%)]\tLoss: 0.441446\n",
      "Train Epoch: 1 [420/700 (60%)]\tLoss: 0.384977\n",
      "Train Epoch: 1 [440/700 (63%)]\tLoss: 0.737386\n",
      "Train Epoch: 1 [460/700 (66%)]\tLoss: 0.818310\n",
      "Train Epoch: 1 [480/700 (69%)]\tLoss: 0.407505\n",
      "Train Epoch: 1 [500/700 (71%)]\tLoss: 0.532746\n",
      "Train Epoch: 1 [520/700 (74%)]\tLoss: 0.540094\n",
      "Train Epoch: 1 [540/700 (77%)]\tLoss: 0.688026\n",
      "Train Epoch: 1 [560/700 (80%)]\tLoss: 0.677418\n",
      "Train Epoch: 1 [580/700 (83%)]\tLoss: 0.495875\n",
      "Train Epoch: 1 [600/700 (86%)]\tLoss: 0.440827\n",
      "Train Epoch: 1 [620/700 (89%)]\tLoss: 0.929426\n",
      "Train Epoch: 1 [640/700 (91%)]\tLoss: 0.733525\n",
      "Train Epoch: 1 [660/700 (94%)]\tLoss: 0.629587\n",
      "Train Epoch: 1 [680/700 (97%)]\tLoss: 0.486923\n",
      "Train Epoch: 2 [0/700 (0%)]\tLoss: 0.367158\n",
      "Train Epoch: 2 [20/700 (3%)]\tLoss: 0.729644\n",
      "Train Epoch: 2 [40/700 (6%)]\tLoss: 0.476359\n",
      "Train Epoch: 2 [60/700 (9%)]\tLoss: 0.719092\n",
      "Train Epoch: 2 [80/700 (11%)]\tLoss: 0.607974\n",
      "Train Epoch: 2 [100/700 (14%)]\tLoss: 0.921871\n",
      "Train Epoch: 2 [120/700 (17%)]\tLoss: 0.570531\n",
      "Train Epoch: 2 [140/700 (20%)]\tLoss: 0.676105\n",
      "Train Epoch: 2 [160/700 (23%)]\tLoss: 0.605496\n",
      "Train Epoch: 2 [180/700 (26%)]\tLoss: 0.343069\n",
      "Train Epoch: 2 [200/700 (29%)]\tLoss: 0.698862\n",
      "Train Epoch: 2 [220/700 (31%)]\tLoss: 0.799433\n",
      "Train Epoch: 2 [240/700 (34%)]\tLoss: 0.420371\n",
      "Train Epoch: 2 [260/700 (37%)]\tLoss: 0.706247\n",
      "Train Epoch: 2 [280/700 (40%)]\tLoss: 0.532558\n",
      "Train Epoch: 2 [300/700 (43%)]\tLoss: 0.637513\n",
      "Train Epoch: 2 [320/700 (46%)]\tLoss: 0.372375\n",
      "Train Epoch: 2 [340/700 (49%)]\tLoss: 0.417230\n",
      "Train Epoch: 2 [360/700 (51%)]\tLoss: 0.624674\n",
      "Train Epoch: 2 [380/700 (54%)]\tLoss: 0.537830\n",
      "Train Epoch: 2 [400/700 (57%)]\tLoss: 0.988757\n",
      "Train Epoch: 2 [420/700 (60%)]\tLoss: 0.645164\n",
      "Train Epoch: 2 [440/700 (63%)]\tLoss: 0.552692\n",
      "Train Epoch: 2 [460/700 (66%)]\tLoss: 0.833366\n",
      "Train Epoch: 2 [480/700 (69%)]\tLoss: 0.614795\n",
      "Train Epoch: 2 [500/700 (71%)]\tLoss: 0.406554\n",
      "Train Epoch: 2 [520/700 (74%)]\tLoss: 0.878214\n",
      "Train Epoch: 2 [540/700 (77%)]\tLoss: 0.867314\n",
      "Train Epoch: 2 [560/700 (80%)]\tLoss: 0.895580\n",
      "Train Epoch: 2 [580/700 (83%)]\tLoss: 0.777107\n",
      "Train Epoch: 2 [600/700 (86%)]\tLoss: 0.853848\n",
      "Train Epoch: 2 [620/700 (89%)]\tLoss: 0.619318\n",
      "Train Epoch: 2 [640/700 (91%)]\tLoss: 0.652942\n",
      "Train Epoch: 2 [660/700 (94%)]\tLoss: 0.600887\n",
      "Train Epoch: 2 [680/700 (97%)]\tLoss: 0.544404\n",
      "Train Epoch: 3 [0/700 (0%)]\tLoss: 0.680909\n",
      "Train Epoch: 3 [20/700 (3%)]\tLoss: 0.525733\n",
      "Train Epoch: 3 [40/700 (6%)]\tLoss: 0.318115\n",
      "Train Epoch: 3 [60/700 (9%)]\tLoss: 0.772635\n",
      "Train Epoch: 3 [80/700 (11%)]\tLoss: 0.740554\n",
      "Train Epoch: 3 [100/700 (14%)]\tLoss: 0.530637\n",
      "Train Epoch: 3 [120/700 (17%)]\tLoss: 0.549226\n",
      "Train Epoch: 3 [140/700 (20%)]\tLoss: 0.541525\n",
      "Train Epoch: 3 [160/700 (23%)]\tLoss: 0.636604\n",
      "Train Epoch: 3 [180/700 (26%)]\tLoss: 0.557819\n",
      "Train Epoch: 3 [200/700 (29%)]\tLoss: 0.686181\n",
      "Train Epoch: 3 [220/700 (31%)]\tLoss: 0.517021\n",
      "Train Epoch: 3 [240/700 (34%)]\tLoss: 0.547996\n",
      "Train Epoch: 3 [260/700 (37%)]\tLoss: 0.706928\n",
      "Train Epoch: 3 [280/700 (40%)]\tLoss: 0.969916\n",
      "Train Epoch: 3 [300/700 (43%)]\tLoss: 0.846481\n",
      "Train Epoch: 3 [320/700 (46%)]\tLoss: 0.513500\n",
      "Train Epoch: 3 [340/700 (49%)]\tLoss: 0.730126\n",
      "Train Epoch: 3 [360/700 (51%)]\tLoss: 0.739437\n",
      "Train Epoch: 3 [380/700 (54%)]\tLoss: 0.510143\n",
      "Train Epoch: 3 [400/700 (57%)]\tLoss: 0.775333\n",
      "Train Epoch: 3 [420/700 (60%)]\tLoss: 0.755817\n",
      "Train Epoch: 3 [440/700 (63%)]\tLoss: 0.481596\n",
      "Train Epoch: 3 [460/700 (66%)]\tLoss: 0.545996\n",
      "Train Epoch: 3 [480/700 (69%)]\tLoss: 0.565010\n",
      "Train Epoch: 3 [500/700 (71%)]\tLoss: 0.512284\n",
      "Train Epoch: 3 [520/700 (74%)]\tLoss: 0.689617\n",
      "Train Epoch: 3 [540/700 (77%)]\tLoss: 0.701479\n",
      "Train Epoch: 3 [560/700 (80%)]\tLoss: 0.500326\n",
      "Train Epoch: 3 [580/700 (83%)]\tLoss: 0.588756\n",
      "Train Epoch: 3 [600/700 (86%)]\tLoss: 0.686275\n",
      "Train Epoch: 3 [620/700 (89%)]\tLoss: 0.551831\n",
      "Train Epoch: 3 [640/700 (91%)]\tLoss: 0.416374\n",
      "Train Epoch: 3 [660/700 (94%)]\tLoss: 0.411803\n",
      "Train Epoch: 3 [680/700 (97%)]\tLoss: 0.515328\n",
      "Train Epoch: 4 [0/700 (0%)]\tLoss: 0.665802\n",
      "Train Epoch: 4 [20/700 (3%)]\tLoss: 0.660012\n",
      "Train Epoch: 4 [40/700 (6%)]\tLoss: 0.590212\n",
      "Train Epoch: 4 [60/700 (9%)]\tLoss: 0.692989\n",
      "Train Epoch: 4 [80/700 (11%)]\tLoss: 0.506117\n",
      "Train Epoch: 4 [100/700 (14%)]\tLoss: 0.717514\n",
      "Train Epoch: 4 [120/700 (17%)]\tLoss: 0.629485\n",
      "Train Epoch: 4 [140/700 (20%)]\tLoss: 0.639494\n",
      "Train Epoch: 4 [160/700 (23%)]\tLoss: 0.975042\n",
      "Train Epoch: 4 [180/700 (26%)]\tLoss: 0.629403\n",
      "Train Epoch: 4 [200/700 (29%)]\tLoss: 0.407151\n",
      "Train Epoch: 4 [220/700 (31%)]\tLoss: 0.688843\n",
      "Train Epoch: 4 [240/700 (34%)]\tLoss: 0.942609\n",
      "Train Epoch: 4 [260/700 (37%)]\tLoss: 0.642567\n",
      "Train Epoch: 4 [280/700 (40%)]\tLoss: 0.678436\n",
      "Train Epoch: 4 [300/700 (43%)]\tLoss: 0.955914\n",
      "Train Epoch: 4 [320/700 (46%)]\tLoss: 0.844771\n",
      "Train Epoch: 4 [340/700 (49%)]\tLoss: 0.780883\n",
      "Train Epoch: 4 [360/700 (51%)]\tLoss: 0.694635\n",
      "Train Epoch: 4 [380/700 (54%)]\tLoss: 0.540842\n",
      "Train Epoch: 4 [400/700 (57%)]\tLoss: 0.629181\n",
      "Train Epoch: 4 [420/700 (60%)]\tLoss: 1.027147\n",
      "Train Epoch: 4 [440/700 (63%)]\tLoss: 0.537713\n",
      "Train Epoch: 4 [460/700 (66%)]\tLoss: 0.737077\n",
      "Train Epoch: 4 [480/700 (69%)]\tLoss: 0.538968\n",
      "Train Epoch: 4 [500/700 (71%)]\tLoss: 0.698448\n",
      "Train Epoch: 4 [520/700 (74%)]\tLoss: 0.487249\n",
      "Train Epoch: 4 [540/700 (77%)]\tLoss: 0.504418\n",
      "Train Epoch: 4 [560/700 (80%)]\tLoss: 0.621280\n",
      "Train Epoch: 4 [580/700 (83%)]\tLoss: 0.581574\n",
      "Train Epoch: 4 [600/700 (86%)]\tLoss: 0.364876\n",
      "Train Epoch: 4 [620/700 (89%)]\tLoss: 0.521885\n",
      "Train Epoch: 4 [640/700 (91%)]\tLoss: 0.417978\n",
      "Train Epoch: 4 [660/700 (94%)]\tLoss: 0.699556\n",
      "Train Epoch: 4 [680/700 (97%)]\tLoss: 0.583636\n",
      "Train Epoch: 5 [0/700 (0%)]\tLoss: 0.343891\n",
      "Train Epoch: 5 [20/700 (3%)]\tLoss: 0.502352\n",
      "Train Epoch: 5 [40/700 (6%)]\tLoss: 0.696333\n",
      "Train Epoch: 5 [60/700 (9%)]\tLoss: 0.621334\n",
      "Train Epoch: 5 [80/700 (11%)]\tLoss: 0.353206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [100/700 (14%)]\tLoss: 0.737128\n",
      "Train Epoch: 5 [120/700 (17%)]\tLoss: 0.592227\n",
      "Train Epoch: 5 [140/700 (20%)]\tLoss: 0.694169\n",
      "Train Epoch: 5 [160/700 (23%)]\tLoss: 0.575614\n",
      "Train Epoch: 5 [180/700 (26%)]\tLoss: 0.535377\n",
      "Train Epoch: 5 [200/700 (29%)]\tLoss: 0.685636\n",
      "Train Epoch: 5 [220/700 (31%)]\tLoss: 0.716494\n",
      "Train Epoch: 5 [240/700 (34%)]\tLoss: 0.499981\n",
      "Train Epoch: 5 [260/700 (37%)]\tLoss: 0.348754\n",
      "Train Epoch: 5 [280/700 (40%)]\tLoss: 0.367250\n",
      "Train Epoch: 5 [300/700 (43%)]\tLoss: 0.515143\n",
      "Train Epoch: 5 [320/700 (46%)]\tLoss: 0.730961\n",
      "Train Epoch: 5 [340/700 (49%)]\tLoss: 0.849045\n",
      "Train Epoch: 5 [360/700 (51%)]\tLoss: 0.732130\n",
      "Train Epoch: 5 [380/700 (54%)]\tLoss: 0.489096\n",
      "Train Epoch: 5 [400/700 (57%)]\tLoss: 0.584027\n",
      "Train Epoch: 5 [420/700 (60%)]\tLoss: 0.520407\n",
      "Train Epoch: 5 [440/700 (63%)]\tLoss: 0.339016\n",
      "Train Epoch: 5 [460/700 (66%)]\tLoss: 0.764418\n",
      "Train Epoch: 5 [480/700 (69%)]\tLoss: 0.504113\n",
      "Train Epoch: 5 [500/700 (71%)]\tLoss: 0.698026\n",
      "Train Epoch: 5 [520/700 (74%)]\tLoss: 0.737667\n",
      "Train Epoch: 5 [540/700 (77%)]\tLoss: 0.509085\n",
      "Train Epoch: 5 [560/700 (80%)]\tLoss: 0.619320\n",
      "Train Epoch: 5 [580/700 (83%)]\tLoss: 0.542843\n",
      "Train Epoch: 5 [600/700 (86%)]\tLoss: 0.704354\n",
      "Train Epoch: 5 [620/700 (89%)]\tLoss: 0.693131\n",
      "Train Epoch: 5 [640/700 (91%)]\tLoss: 0.609948\n",
      "Train Epoch: 5 [660/700 (94%)]\tLoss: 0.453776\n",
      "Train Epoch: 5 [680/700 (97%)]\tLoss: 0.963845\n",
      "Train Epoch: 6 [0/700 (0%)]\tLoss: 0.699832\n",
      "Train Epoch: 6 [20/700 (3%)]\tLoss: 0.512626\n",
      "Train Epoch: 6 [40/700 (6%)]\tLoss: 0.511090\n",
      "Train Epoch: 6 [60/700 (9%)]\tLoss: 0.505716\n",
      "Train Epoch: 6 [80/700 (11%)]\tLoss: 0.497152\n",
      "Train Epoch: 6 [100/700 (14%)]\tLoss: 1.002886\n",
      "Train Epoch: 6 [120/700 (17%)]\tLoss: 0.770202\n",
      "Train Epoch: 6 [140/700 (20%)]\tLoss: 0.790963\n",
      "Train Epoch: 6 [160/700 (23%)]\tLoss: 0.511972\n",
      "Train Epoch: 6 [180/700 (26%)]\tLoss: 0.538636\n",
      "Train Epoch: 6 [200/700 (29%)]\tLoss: 0.408999\n",
      "Train Epoch: 6 [220/700 (31%)]\tLoss: 0.707938\n",
      "Train Epoch: 6 [240/700 (34%)]\tLoss: 0.691205\n",
      "Train Epoch: 6 [260/700 (37%)]\tLoss: 0.616179\n",
      "Train Epoch: 6 [280/700 (40%)]\tLoss: 0.421627\n",
      "Train Epoch: 6 [300/700 (43%)]\tLoss: 0.726147\n",
      "Train Epoch: 6 [320/700 (46%)]\tLoss: 0.694950\n",
      "Train Epoch: 6 [340/700 (49%)]\tLoss: 0.517326\n",
      "Train Epoch: 6 [360/700 (51%)]\tLoss: 0.910002\n",
      "Train Epoch: 6 [380/700 (54%)]\tLoss: 0.637425\n",
      "Train Epoch: 6 [400/700 (57%)]\tLoss: 0.648709\n",
      "Train Epoch: 6 [420/700 (60%)]\tLoss: 0.505296\n",
      "Train Epoch: 6 [440/700 (63%)]\tLoss: 0.520720\n",
      "Train Epoch: 6 [460/700 (66%)]\tLoss: 0.538686\n",
      "Train Epoch: 6 [480/700 (69%)]\tLoss: 0.549099\n",
      "Train Epoch: 6 [500/700 (71%)]\tLoss: 0.608873\n",
      "Train Epoch: 6 [520/700 (74%)]\tLoss: 0.616182\n",
      "Train Epoch: 6 [540/700 (77%)]\tLoss: 0.699081\n",
      "Train Epoch: 6 [560/700 (80%)]\tLoss: 0.822124\n",
      "Train Epoch: 6 [580/700 (83%)]\tLoss: 0.655230\n",
      "Train Epoch: 6 [600/700 (86%)]\tLoss: 0.551264\n",
      "Train Epoch: 6 [620/700 (89%)]\tLoss: 0.533894\n",
      "Train Epoch: 6 [640/700 (91%)]\tLoss: 0.549153\n",
      "Train Epoch: 6 [660/700 (94%)]\tLoss: 0.445109\n",
      "Train Epoch: 6 [680/700 (97%)]\tLoss: 0.986513\n",
      "Train Epoch: 7 [0/700 (0%)]\tLoss: 0.508389\n",
      "Train Epoch: 7 [20/700 (3%)]\tLoss: 0.508647\n",
      "Train Epoch: 7 [40/700 (6%)]\tLoss: 0.503541\n",
      "Train Epoch: 7 [60/700 (9%)]\tLoss: 0.442670\n",
      "Train Epoch: 7 [80/700 (11%)]\tLoss: 0.581267\n",
      "Train Epoch: 7 [100/700 (14%)]\tLoss: 0.708524\n",
      "Train Epoch: 7 [120/700 (17%)]\tLoss: 0.703150\n",
      "Train Epoch: 7 [140/700 (20%)]\tLoss: 0.609982\n",
      "Train Epoch: 7 [160/700 (23%)]\tLoss: 0.762798\n",
      "Train Epoch: 7 [180/700 (26%)]\tLoss: 0.720724\n",
      "Train Epoch: 7 [200/700 (29%)]\tLoss: 0.536061\n",
      "Train Epoch: 7 [220/700 (31%)]\tLoss: 0.683248\n",
      "Train Epoch: 7 [240/700 (34%)]\tLoss: 0.628239\n",
      "Train Epoch: 7 [260/700 (37%)]\tLoss: 0.328312\n",
      "Train Epoch: 7 [280/700 (40%)]\tLoss: 0.704218\n",
      "Train Epoch: 7 [300/700 (43%)]\tLoss: 0.504676\n",
      "Train Epoch: 7 [320/700 (46%)]\tLoss: 0.752671\n",
      "Train Epoch: 7 [340/700 (49%)]\tLoss: 0.519427\n",
      "Train Epoch: 7 [360/700 (51%)]\tLoss: 0.323148\n",
      "Train Epoch: 7 [380/700 (54%)]\tLoss: 0.516221\n",
      "Train Epoch: 7 [400/700 (57%)]\tLoss: 0.724566\n",
      "Train Epoch: 7 [420/700 (60%)]\tLoss: 0.433334\n",
      "Train Epoch: 7 [440/700 (63%)]\tLoss: 0.687855\n",
      "Train Epoch: 7 [460/700 (66%)]\tLoss: 0.697275\n",
      "Train Epoch: 7 [480/700 (69%)]\tLoss: 0.508210\n",
      "Train Epoch: 7 [500/700 (71%)]\tLoss: 0.697559\n",
      "Train Epoch: 7 [520/700 (74%)]\tLoss: 0.700000\n",
      "Train Epoch: 7 [540/700 (77%)]\tLoss: 0.656079\n",
      "Train Epoch: 7 [560/700 (80%)]\tLoss: 0.510722\n",
      "Train Epoch: 7 [580/700 (83%)]\tLoss: 1.003140\n",
      "Train Epoch: 7 [600/700 (86%)]\tLoss: 0.535687\n",
      "Train Epoch: 7 [620/700 (89%)]\tLoss: 0.506404\n",
      "Train Epoch: 7 [640/700 (91%)]\tLoss: 0.536834\n",
      "Train Epoch: 7 [660/700 (94%)]\tLoss: 0.510505\n",
      "Train Epoch: 7 [680/700 (97%)]\tLoss: 0.693421\n",
      "Train Epoch: 8 [0/700 (0%)]\tLoss: 0.322695\n",
      "Train Epoch: 8 [20/700 (3%)]\tLoss: 0.528763\n",
      "Train Epoch: 8 [40/700 (6%)]\tLoss: 0.545326\n",
      "Train Epoch: 8 [60/700 (9%)]\tLoss: 0.900764\n",
      "Train Epoch: 8 [80/700 (11%)]\tLoss: 0.758731\n",
      "Train Epoch: 8 [100/700 (14%)]\tLoss: 0.517542\n",
      "Train Epoch: 8 [120/700 (17%)]\tLoss: 0.537669\n",
      "Train Epoch: 8 [140/700 (20%)]\tLoss: 0.636929\n",
      "Train Epoch: 8 [160/700 (23%)]\tLoss: 0.504551\n",
      "Train Epoch: 8 [180/700 (26%)]\tLoss: 0.469465\n",
      "Train Epoch: 8 [200/700 (29%)]\tLoss: 0.550278\n",
      "Train Epoch: 8 [220/700 (31%)]\tLoss: 0.506614\n",
      "Train Epoch: 8 [240/700 (34%)]\tLoss: 0.615725\n",
      "Train Epoch: 8 [260/700 (37%)]\tLoss: 0.696937\n",
      "Train Epoch: 8 [280/700 (40%)]\tLoss: 0.655666\n",
      "Train Epoch: 8 [300/700 (43%)]\tLoss: 0.700321\n",
      "Train Epoch: 8 [320/700 (46%)]\tLoss: 0.702328\n",
      "Train Epoch: 8 [340/700 (49%)]\tLoss: 0.507625\n",
      "Train Epoch: 8 [360/700 (51%)]\tLoss: 0.323756\n",
      "Train Epoch: 8 [380/700 (54%)]\tLoss: 0.506232\n",
      "Train Epoch: 8 [400/700 (57%)]\tLoss: 0.696556\n",
      "Train Epoch: 8 [420/700 (60%)]\tLoss: 0.313692\n",
      "Train Epoch: 8 [440/700 (63%)]\tLoss: 0.313868\n",
      "Train Epoch: 8 [460/700 (66%)]\tLoss: 0.586579\n",
      "Train Epoch: 8 [480/700 (69%)]\tLoss: 0.502385\n",
      "Train Epoch: 8 [500/700 (71%)]\tLoss: 0.550361\n",
      "Train Epoch: 8 [520/700 (74%)]\tLoss: 0.391729\n",
      "Train Epoch: 8 [540/700 (77%)]\tLoss: 0.955345\n",
      "Train Epoch: 8 [560/700 (80%)]\tLoss: 0.967296\n",
      "Train Epoch: 8 [580/700 (83%)]\tLoss: 0.533011\n",
      "Train Epoch: 8 [600/700 (86%)]\tLoss: 0.479126\n",
      "Train Epoch: 8 [620/700 (89%)]\tLoss: 0.693615\n",
      "Train Epoch: 8 [640/700 (91%)]\tLoss: 0.634862\n",
      "Train Epoch: 8 [660/700 (94%)]\tLoss: 0.932600\n",
      "Train Epoch: 8 [680/700 (97%)]\tLoss: 0.738153\n",
      "Train Epoch: 9 [0/700 (0%)]\tLoss: 0.707942\n",
      "Train Epoch: 9 [20/700 (3%)]\tLoss: 0.504176\n",
      "Train Epoch: 9 [40/700 (6%)]\tLoss: 0.991110\n",
      "Train Epoch: 9 [60/700 (9%)]\tLoss: 0.693319\n",
      "Train Epoch: 9 [80/700 (11%)]\tLoss: 0.639538\n",
      "Train Epoch: 9 [100/700 (14%)]\tLoss: 0.700312\n",
      "Train Epoch: 9 [120/700 (17%)]\tLoss: 0.689782\n",
      "Train Epoch: 9 [140/700 (20%)]\tLoss: 0.503456\n",
      "Train Epoch: 9 [160/700 (23%)]\tLoss: 0.691164\n",
      "Train Epoch: 9 [180/700 (26%)]\tLoss: 0.673260\n",
      "Train Epoch: 9 [200/700 (29%)]\tLoss: 0.765211\n",
      "Train Epoch: 9 [220/700 (31%)]\tLoss: 0.692745\n",
      "Train Epoch: 9 [240/700 (34%)]\tLoss: 0.556343\n",
      "Train Epoch: 9 [260/700 (37%)]\tLoss: 0.701240\n",
      "Train Epoch: 9 [280/700 (40%)]\tLoss: 0.540676\n",
      "Train Epoch: 9 [300/700 (43%)]\tLoss: 0.738689\n",
      "Train Epoch: 9 [320/700 (46%)]\tLoss: 0.607232\n",
      "Train Epoch: 9 [340/700 (49%)]\tLoss: 0.693788\n",
      "Train Epoch: 9 [360/700 (51%)]\tLoss: 0.510093\n",
      "Train Epoch: 9 [380/700 (54%)]\tLoss: 0.888459\n",
      "Train Epoch: 9 [400/700 (57%)]\tLoss: 0.503172\n",
      "Train Epoch: 9 [420/700 (60%)]\tLoss: 0.693190\n",
      "Train Epoch: 9 [440/700 (63%)]\tLoss: 0.422520\n",
      "Train Epoch: 9 [460/700 (66%)]\tLoss: 0.588009\n",
      "Train Epoch: 9 [480/700 (69%)]\tLoss: 0.703632\n",
      "Train Epoch: 9 [500/700 (71%)]\tLoss: 0.911544\n",
      "Train Epoch: 9 [520/700 (74%)]\tLoss: 0.504129\n",
      "Train Epoch: 9 [540/700 (77%)]\tLoss: 0.995155\n",
      "Train Epoch: 9 [560/700 (80%)]\tLoss: 0.911353\n",
      "Train Epoch: 9 [580/700 (83%)]\tLoss: 0.517751\n",
      "Train Epoch: 9 [600/700 (86%)]\tLoss: 0.458013\n",
      "Train Epoch: 9 [620/700 (89%)]\tLoss: 0.525754\n",
      "Train Epoch: 9 [640/700 (91%)]\tLoss: 0.503377\n",
      "Train Epoch: 9 [660/700 (94%)]\tLoss: 0.850837\n",
      "Train Epoch: 9 [680/700 (97%)]\tLoss: 0.512098\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        resized_target = target.view(output.shape[0], -1)\n",
    "        loss = criterion(output, resized_target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "classes = (True, False)\n",
    "\n",
    "def boolean_output(output):\n",
    "    return bool(output.view(1) > torch.tensor([0.5]))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            bool_output = boolean_output(output)\n",
    "            bool_target = bool(target)\n",
    "            y_test.append(bool_target)\n",
    "            y_pred.append(bool_output)\n",
    "            if bool_output == bool_target:\n",
    "                correct += 1\n",
    "    accuracy = correct/len(test_loader.dataset)\n",
    "    print(f\"accuracy: {accuracy}\")\n",
    "    # Confusion matrix\n",
    "    confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(confusion_mtx, classes=classes, normalize=True,\n",
    "                          title='Confusion matrix')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8235294117647058\n",
      "[[39  2]\n",
      " [10 17]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(model, \"cpu\", test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
