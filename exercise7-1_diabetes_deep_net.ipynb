{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabeteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        xy = np.loadtxt(csv_file, delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.tensor(torch.from_numpy(xy[:, 0:-1]))\n",
    "        self.y_data = torch.tensor(torch.from_numpy(xy[:, [-1]]))\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = DiabeteDataset('diabetes_train.csv') # 768 rows\n",
    "train_dataset = DiabeteDataset('diabetes.csv') # 768 rows\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=8, shuffle=True, num_workers=2) # 768 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDeep(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Input layer is (8 , 8)\n",
    "        Hidder layer is (8, 8)\n",
    "        Ouput layser is (8, 1)\n",
    "        3 layers loss is ~5\n",
    "        8 layers loss is ~4\n",
    "        21 layer losss is ~4\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 8)\n",
    "        self.l2 = torch.nn.Linear(8, 8)\n",
    "        self.l3 = torch.nn.Linear(8, 8)\n",
    "        self.l4 = torch.nn.Linear(8, 8)\n",
    "        self.l5 = torch.nn.Linear(8, 8)\n",
    "        self.l6 = torch.nn.Linear(8, 8)\n",
    "        self.l7 = torch.nn.Linear(8, 8)\n",
    "        self.l8 = torch.nn.Linear(8, 8)\n",
    "        self.l9 = torch.nn.Linear(8, 8)\n",
    "        self.l10 = torch.nn.Linear(8, 8)\n",
    "        self.l11 = torch.nn.Linear(8, 8)\n",
    "        self.l12 = torch.nn.Linear(8, 8)\n",
    "        self.l13 = torch.nn.Linear(8, 8)\n",
    "        self.l14 = torch.nn.Linear(8, 8)\n",
    "        self.l15 = torch.nn.Linear(8, 8)\n",
    "        self.l16 = torch.nn.Linear(8, 8)\n",
    "        self.l17 = torch.nn.Linear(8, 8)\n",
    "        self.l18 = torch.nn.Linear(8, 8)\n",
    "        self.l19 = torch.nn.Linear(8, 8)\n",
    "        self.l20 = torch.nn.Linear(8, 8)\n",
    "        self.l21 = torch.nn.Linear(8, 1)\n",
    "    \n",
    "        # Activation function\n",
    "        self.activation_fn = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.l1(x))\n",
    "        x = self.activation_fn(self.l2(x))\n",
    "        x = self.activation_fn(self.l3(x))\n",
    "        x = self.activation_fn(self.l4(x))\n",
    "        x = self.activation_fn(self.l5(x))\n",
    "        x = self.activation_fn(self.l6(x))\n",
    "        x = self.activation_fn(self.l7(x))\n",
    "        x = self.activation_fn(self.l8(x))\n",
    "        x = self.activation_fn(self.l9(x))\n",
    "        x = self.activation_fn(self.l10(x))        \n",
    "        x = self.activation_fn(self.l11(x))\n",
    "        x = self.activation_fn(self.l12(x))        \n",
    "        x = self.activation_fn(self.l13(x))\n",
    "        x = self.activation_fn(self.l14(x))\n",
    "        x = self.activation_fn(self.l15(x))\n",
    "        x = self.activation_fn(self.l16(x))        \n",
    "        x = self.activation_fn(self.l17(x))\n",
    "        x = self.activation_fn(self.l18(x))        \n",
    "        x = self.activation_fn(self.l19(x))\n",
    "        x = self.activation_fn(self.l20(x))        \n",
    "        x = self.activation_fn(self.l21(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWide(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 60)\n",
    "        self.l2 = torch.nn.Linear(60, 60)\n",
    "        self.l3 = torch.nn.Linear(60, 60)\n",
    "        self.l4 = torch.nn.Linear(60, 60)\n",
    "        self.l5 = torch.nn.Linear(60, 60)\n",
    "        self.l6 = torch.nn.Linear(60, 60)\n",
    "        self.l7 = torch.nn.Linear(60, 60)\n",
    "        self.l8 = torch.nn.Linear(60, 60)\n",
    "        self.l9 = torch.nn.Linear(60, 60)\n",
    "        self.l10 = torch.nn.Linear(60, 60)\n",
    "        self.l11 = torch.nn.Linear(60, 60)\n",
    "        self.l12 = torch.nn.Linear(60, 60)\n",
    "        self.l13 = torch.nn.Linear(60, 60)\n",
    "        self.l14 = torch.nn.Linear(60, 1)\n",
    "    \n",
    "        # Activation function\n",
    "        self.activation_fn = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.l1(x))\n",
    "        x = self.activation_fn(self.l2(x))\n",
    "        x = self.activation_fn(self.l3(x))\n",
    "        x = self.activation_fn(self.l4(x))\n",
    "        x = self.activation_fn(self.l5(x))\n",
    "        x = self.activation_fn(self.l6(x))\n",
    "        x = self.activation_fn(self.l7(x))\n",
    "        x = self.activation_fn(self.l8(x))\n",
    "        x = self.activation_fn(self.l9(x))\n",
    "        x = self.activation_fn(self.l10(x))        \n",
    "        x = self.activation_fn(self.l11(x))\n",
    "        x = self.activation_fn(self.l12(x))        \n",
    "        x = self.activation_fn(self.l13(x))\n",
    "        x = self.activation_fn(self.l14(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWide()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/768 (0%)]\tLoss: 0.720566\n",
      "Train Epoch: 0 [80/768 (10%)]\tLoss: 0.698667\n",
      "Train Epoch: 0 [160/768 (21%)]\tLoss: 0.693147\n",
      "Train Epoch: 0 [240/768 (31%)]\tLoss: 0.693147\n",
      "Train Epoch: 0 [320/768 (42%)]\tLoss: 0.693147\n",
      "Train Epoch: 0 [400/768 (52%)]\tLoss: 0.693147\n",
      "Train Epoch: 0 [480/768 (62%)]\tLoss: 0.693147\n",
      "Train Epoch: 0 [560/768 (73%)]\tLoss: 0.693147\n",
      "Train Epoch: 0 [640/768 (83%)]\tLoss: 0.693147\n",
      "Train Epoch: 0 [720/768 (94%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [0/768 (0%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [80/768 (10%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [160/768 (21%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [240/768 (31%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [320/768 (42%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [400/768 (52%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [480/768 (62%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [560/768 (73%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [640/768 (83%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [720/768 (94%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [0/768 (0%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [80/768 (10%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [160/768 (21%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [240/768 (31%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [320/768 (42%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [400/768 (52%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [480/768 (62%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [560/768 (73%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [640/768 (83%)]\tLoss: 0.693147\n",
      "Train Epoch: 2 [720/768 (94%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [0/768 (0%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [80/768 (10%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [160/768 (21%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [240/768 (31%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [320/768 (42%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [400/768 (52%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [480/768 (62%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [560/768 (73%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [640/768 (83%)]\tLoss: 0.693147\n",
      "Train Epoch: 3 [720/768 (94%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [0/768 (0%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [80/768 (10%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [160/768 (21%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [240/768 (31%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [320/768 (42%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [400/768 (52%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [480/768 (62%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [560/768 (73%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [640/768 (83%)]\tLoss: 0.693147\n",
      "Train Epoch: 4 [720/768 (94%)]\tLoss: 0.693147\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
