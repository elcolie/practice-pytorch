{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabeteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        xy = np.loadtxt(csv_file, delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.from_numpy(xy[:, 0:-1]).clone().detach()\n",
    "        self.y_data = torch.from_numpy(xy[:, [-1]]).clone().detach()\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "        return  self.x_data[index], bool(int(self.y_data[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI\n",
    "https://github.com/MateLabs/Public-Datasets/blob/master/Datasets/diabetes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampler import ImbalancedDatasetSampler\n",
    "\n",
    "# train_dataset = DiabeteDataset('diabetes_train.csv') # 768 rows\n",
    "\n",
    "train_dataset = DiabeteDataset('diabetes_train.csv')\n",
    "test_dataset = DiabeteDataset('diabetes_test.csv')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=2, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelDeep(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Input layer is (8 , 8)\n",
    "        Hidder layer is (8, 8)\n",
    "        Ouput layser is (8, 1)\n",
    "        3 layers loss is ~5\n",
    "        8 layers loss is ~4\n",
    "        21 layer losss is ~4\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 8)\n",
    "        self.l2 = torch.nn.Linear(8, 8)\n",
    "        self.l3 = torch.nn.Linear(8, 8)\n",
    "        self.l4 = torch.nn.Linear(8, 8)\n",
    "        self.l5 = torch.nn.Linear(8, 8)\n",
    "        self.l6 = torch.nn.Linear(8, 8)\n",
    "        self.l7 = torch.nn.Linear(8, 8)\n",
    "        self.l8 = torch.nn.Linear(8, 8)\n",
    "        self.l9 = torch.nn.Linear(8, 8)\n",
    "        self.l10 = torch.nn.Linear(8, 8)\n",
    "        self.l11 = torch.nn.Linear(8, 8)\n",
    "        self.l12 = torch.nn.Linear(8, 8)\n",
    "        self.l13 = torch.nn.Linear(8, 8)\n",
    "        self.l14 = torch.nn.Linear(8, 8)\n",
    "        self.l15 = torch.nn.Linear(8, 8)\n",
    "        self.l16 = torch.nn.Linear(8, 8)\n",
    "        self.l17 = torch.nn.Linear(8, 8)\n",
    "        self.l18 = torch.nn.Linear(8, 8)\n",
    "        self.l19 = torch.nn.Linear(8, 8)\n",
    "        self.l20 = torch.nn.Linear(8, 8)\n",
    "        self.l21 = torch.nn.Linear(8, 1)\n",
    "    \n",
    "        # Activation function\n",
    "        self.activation_fn = torch.nn.LeakyReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.l1(x))\n",
    "        x = self.activation_fn(self.l2(x))\n",
    "        x = self.activation_fn(self.l3(x))\n",
    "        x = self.activation_fn(self.l4(x))\n",
    "        x = self.activation_fn(self.l5(x))\n",
    "        x = self.activation_fn(self.l6(x))\n",
    "        x = self.activation_fn(self.l7(x))\n",
    "        x = self.activation_fn(self.l8(x))\n",
    "        x = self.activation_fn(self.l9(x))\n",
    "        x = self.activation_fn(self.l10(x))        \n",
    "        x = self.activation_fn(self.l11(x))\n",
    "        x = self.activation_fn(self.l12(x))        \n",
    "        x = self.activation_fn(self.l13(x))\n",
    "        x = self.activation_fn(self.l14(x))\n",
    "        x = self.activation_fn(self.l15(x))\n",
    "        x = self.activation_fn(self.l16(x))        \n",
    "        x = self.activation_fn(self.l17(x))\n",
    "        x = self.activation_fn(self.l18(x))        \n",
    "        x = self.activation_fn(self.l19(x))\n",
    "        x = self.activation_fn(self.l20(x))        \n",
    "        x = self.sigmoid(self.l21(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWide(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 60)\n",
    "        self.l2 = torch.nn.Linear(60, 60)\n",
    "        self.l3 = torch.nn.Linear(60, 60)\n",
    "        self.l4 = torch.nn.Linear(60, 60)\n",
    "        self.l5 = torch.nn.Linear(60, 60)\n",
    "        self.l6 = torch.nn.Linear(60, 60)\n",
    "        self.l7 = torch.nn.Linear(60, 60)\n",
    "        self.l8 = torch.nn.Linear(60, 60)\n",
    "        self.l9 = torch.nn.Linear(60, 60)\n",
    "        self.l10 = torch.nn.Linear(60, 60)\n",
    "        self.l11 = torch.nn.Linear(60, 60)\n",
    "        self.l12 = torch.nn.Linear(60, 60)\n",
    "        self.l13 = torch.nn.Linear(60, 60)\n",
    "        self.l14 = torch.nn.Linear(60, 1)\n",
    "    \n",
    "        # Activation function\n",
    "        self.activation_fn = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.l1(x))\n",
    "        x = self.activation_fn(self.l2(x))\n",
    "        x = self.activation_fn(self.l3(x))\n",
    "        x = self.activation_fn(self.l4(x))\n",
    "        x = self.activation_fn(self.l5(x))\n",
    "        x = self.activation_fn(self.l6(x))\n",
    "        x = self.activation_fn(self.l7(x))\n",
    "        x = self.activation_fn(self.l8(x))\n",
    "        x = self.activation_fn(self.l9(x))\n",
    "        x = self.activation_fn(self.l10(x))        \n",
    "        x = self.activation_fn(self.l11(x))\n",
    "        x = self.activation_fn(self.l12(x))        \n",
    "        x = self.activation_fn(self.l13(x))\n",
    "        x = self.activation_fn(self.l14(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KopxionAkramsystems(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    loss ~0.6\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 32)\n",
    "        self.l2 = torch.nn.Linear(32, 16)\n",
    "        self.l3 = torch.nn.Linear(16, 1)\n",
    "        self.activation_fn = torch.nn.LeakyReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.l1(x))\n",
    "        x = self.activation_fn(self.l2(x))\n",
    "        x = self.sigmoid(self.l3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelDeep()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/700 (0%)]\tLoss: 0.472662\n",
      "Train Epoch: 0 [20/700 (3%)]\tLoss: 0.978356\n",
      "Train Epoch: 0 [40/700 (6%)]\tLoss: 0.724691\n",
      "Train Epoch: 0 [60/700 (9%)]\tLoss: 0.724214\n",
      "Train Epoch: 0 [80/700 (11%)]\tLoss: 0.473785\n",
      "Train Epoch: 0 [100/700 (14%)]\tLoss: 0.473232\n",
      "Train Epoch: 0 [120/700 (17%)]\tLoss: 0.975224\n",
      "Train Epoch: 0 [140/700 (20%)]\tLoss: 0.723977\n",
      "Train Epoch: 0 [160/700 (23%)]\tLoss: 0.723181\n",
      "Train Epoch: 0 [180/700 (26%)]\tLoss: 0.722664\n",
      "Train Epoch: 0 [200/700 (29%)]\tLoss: 0.964439\n",
      "Train Epoch: 0 [220/700 (31%)]\tLoss: 0.721473\n",
      "Train Epoch: 0 [240/700 (34%)]\tLoss: 0.720601\n",
      "Train Epoch: 0 [260/700 (37%)]\tLoss: 0.950241\n",
      "Train Epoch: 0 [280/700 (40%)]\tLoss: 0.490267\n",
      "Train Epoch: 0 [300/700 (43%)]\tLoss: 0.946989\n",
      "Train Epoch: 0 [320/700 (46%)]\tLoss: 0.943802\n",
      "Train Epoch: 0 [340/700 (49%)]\tLoss: 0.716987\n",
      "Train Epoch: 0 [360/700 (51%)]\tLoss: 0.716082\n",
      "Train Epoch: 0 [380/700 (54%)]\tLoss: 0.715385\n",
      "Train Epoch: 0 [400/700 (57%)]\tLoss: 0.925740\n",
      "Train Epoch: 0 [420/700 (60%)]\tLoss: 0.715300\n",
      "Train Epoch: 0 [440/700 (63%)]\tLoss: 0.715464\n",
      "Train Epoch: 0 [460/700 (66%)]\tLoss: 0.504000\n",
      "Train Epoch: 0 [480/700 (69%)]\tLoss: 0.504327\n",
      "Train Epoch: 0 [500/700 (71%)]\tLoss: 0.714998\n",
      "Train Epoch: 0 [520/700 (74%)]\tLoss: 0.508068\n",
      "Train Epoch: 0 [540/700 (77%)]\tLoss: 0.713605\n",
      "Train Epoch: 0 [560/700 (80%)]\tLoss: 0.912632\n",
      "Train Epoch: 0 [580/700 (83%)]\tLoss: 0.711930\n",
      "Train Epoch: 0 [600/700 (86%)]\tLoss: 0.711133\n",
      "Train Epoch: 0 [620/700 (89%)]\tLoss: 0.710405\n",
      "Train Epoch: 0 [640/700 (91%)]\tLoss: 0.891030\n",
      "Train Epoch: 0 [660/700 (94%)]\tLoss: 0.881989\n",
      "Train Epoch: 0 [680/700 (97%)]\tLoss: 0.869335\n",
      "Train Epoch: 1 [0/700 (0%)]\tLoss: 0.852490\n",
      "Train Epoch: 1 [20/700 (3%)]\tLoss: 0.701638\n",
      "Train Epoch: 1 [40/700 (6%)]\tLoss: 0.812849\n",
      "Train Epoch: 1 [60/700 (9%)]\tLoss: 0.791223\n",
      "Train Epoch: 1 [80/700 (11%)]\tLoss: 0.695537\n",
      "Train Epoch: 1 [100/700 (14%)]\tLoss: 0.695061\n",
      "Train Epoch: 1 [120/700 (17%)]\tLoss: 0.749064\n",
      "Train Epoch: 1 [140/700 (20%)]\tLoss: 0.746840\n",
      "Train Epoch: 1 [160/700 (23%)]\tLoss: 0.645344\n",
      "Train Epoch: 1 [180/700 (26%)]\tLoss: 0.694012\n",
      "Train Epoch: 1 [200/700 (29%)]\tLoss: 0.693454\n",
      "Train Epoch: 1 [220/700 (31%)]\tLoss: 0.693256\n",
      "Train Epoch: 1 [240/700 (34%)]\tLoss: 0.693214\n",
      "Train Epoch: 1 [260/700 (37%)]\tLoss: 0.693217\n",
      "Train Epoch: 1 [280/700 (40%)]\tLoss: 0.705550\n",
      "Train Epoch: 1 [300/700 (43%)]\tLoss: 0.693251\n",
      "Train Epoch: 1 [320/700 (46%)]\tLoss: 0.693202\n",
      "Train Epoch: 1 [340/700 (49%)]\tLoss: 0.700524\n",
      "Train Epoch: 1 [360/700 (51%)]\tLoss: 0.698162\n",
      "Train Epoch: 1 [380/700 (54%)]\tLoss: 0.697432\n",
      "Train Epoch: 1 [400/700 (57%)]\tLoss: 0.693147\n",
      "Train Epoch: 1 [420/700 (60%)]\tLoss: 0.696344\n",
      "Train Epoch: 1 [440/700 (63%)]\tLoss: 0.690049\n",
      "Train Epoch: 1 [460/700 (66%)]\tLoss: 0.696294\n",
      "Train Epoch: 1 [480/700 (69%)]\tLoss: 0.690179\n",
      "Train Epoch: 1 [500/700 (71%)]\tLoss: 0.689899\n",
      "Train Epoch: 1 [520/700 (74%)]\tLoss: 0.693115\n",
      "Train Epoch: 1 [540/700 (77%)]\tLoss: 0.696298\n",
      "Train Epoch: 1 [560/700 (80%)]\tLoss: 0.690664\n",
      "Train Epoch: 1 [580/700 (83%)]\tLoss: 0.693149\n",
      "Train Epoch: 1 [600/700 (86%)]\tLoss: 0.691166\n",
      "Train Epoch: 1 [620/700 (89%)]\tLoss: 0.695185\n",
      "Train Epoch: 1 [640/700 (91%)]\tLoss: 0.693209\n",
      "Train Epoch: 1 [660/700 (94%)]\tLoss: 0.693157\n",
      "Train Epoch: 1 [680/700 (97%)]\tLoss: 0.693009\n",
      "Train Epoch: 2 [0/700 (0%)]\tLoss: 0.693003\n",
      "Train Epoch: 2 [20/700 (3%)]\tLoss: 0.695793\n",
      "Train Epoch: 2 [40/700 (6%)]\tLoss: 0.693227\n",
      "Train Epoch: 2 [60/700 (9%)]\tLoss: 0.690162\n",
      "Train Epoch: 2 [80/700 (11%)]\tLoss: 0.690654\n",
      "Train Epoch: 2 [100/700 (14%)]\tLoss: 0.692991\n",
      "Train Epoch: 2 [120/700 (17%)]\tLoss: 0.690917\n",
      "Train Epoch: 2 [140/700 (20%)]\tLoss: 0.693063\n",
      "Train Epoch: 2 [160/700 (23%)]\tLoss: 0.693100\n",
      "Train Epoch: 2 [180/700 (26%)]\tLoss: 0.693164\n",
      "Train Epoch: 2 [200/700 (29%)]\tLoss: 0.690480\n",
      "Train Epoch: 2 [220/700 (31%)]\tLoss: 0.690451\n",
      "Train Epoch: 2 [240/700 (34%)]\tLoss: 0.692783\n",
      "Train Epoch: 2 [260/700 (37%)]\tLoss: 0.695255\n",
      "Train Epoch: 2 [280/700 (40%)]\tLoss: 0.694897\n",
      "Train Epoch: 2 [300/700 (43%)]\tLoss: 0.694702\n",
      "Train Epoch: 2 [320/700 (46%)]\tLoss: 0.695098\n",
      "Train Epoch: 2 [340/700 (49%)]\tLoss: 0.695102\n",
      "Train Epoch: 2 [360/700 (51%)]\tLoss: 0.692710\n",
      "Train Epoch: 2 [380/700 (54%)]\tLoss: 0.691637\n",
      "Train Epoch: 2 [400/700 (57%)]\tLoss: 0.691537\n",
      "Train Epoch: 2 [420/700 (60%)]\tLoss: 0.692210\n",
      "Train Epoch: 2 [440/700 (63%)]\tLoss: 0.692516\n",
      "Train Epoch: 2 [460/700 (66%)]\tLoss: 0.694580\n",
      "Train Epoch: 2 [480/700 (69%)]\tLoss: 0.692531\n",
      "Train Epoch: 2 [500/700 (71%)]\tLoss: 0.689358\n",
      "Train Epoch: 2 [520/700 (74%)]\tLoss: 0.692514\n",
      "Train Epoch: 2 [540/700 (77%)]\tLoss: 0.696134\n",
      "Train Epoch: 2 [560/700 (80%)]\tLoss: 0.692550\n",
      "Train Epoch: 2 [580/700 (83%)]\tLoss: 0.693956\n",
      "Train Epoch: 2 [600/700 (86%)]\tLoss: 0.692697\n",
      "Train Epoch: 2 [620/700 (89%)]\tLoss: 0.691004\n",
      "Train Epoch: 2 [640/700 (91%)]\tLoss: 0.697133\n",
      "Train Epoch: 2 [660/700 (94%)]\tLoss: 0.692732\n",
      "Train Epoch: 2 [680/700 (97%)]\tLoss: 0.693235\n",
      "Train Epoch: 3 [0/700 (0%)]\tLoss: 0.690671\n",
      "Train Epoch: 3 [20/700 (3%)]\tLoss: 0.694899\n",
      "Train Epoch: 3 [40/700 (6%)]\tLoss: 0.692809\n",
      "Train Epoch: 3 [60/700 (9%)]\tLoss: 0.682663\n",
      "Train Epoch: 3 [80/700 (11%)]\tLoss: 0.701717\n",
      "Train Epoch: 3 [100/700 (14%)]\tLoss: 0.684228\n",
      "Train Epoch: 3 [120/700 (17%)]\tLoss: 0.693519\n",
      "Train Epoch: 3 [140/700 (20%)]\tLoss: 0.693176\n",
      "Train Epoch: 3 [160/700 (23%)]\tLoss: 0.715736\n",
      "Train Epoch: 3 [180/700 (26%)]\tLoss: 0.688137\n",
      "Train Epoch: 3 [200/700 (29%)]\tLoss: 0.649660\n",
      "Train Epoch: 3 [220/700 (31%)]\tLoss: 0.719563\n",
      "Train Epoch: 3 [240/700 (34%)]\tLoss: 0.693168\n",
      "Train Epoch: 3 [260/700 (37%)]\tLoss: 0.735064\n",
      "Train Epoch: 3 [280/700 (40%)]\tLoss: 0.733012\n",
      "Train Epoch: 3 [300/700 (43%)]\tLoss: 0.693136\n",
      "Train Epoch: 3 [320/700 (46%)]\tLoss: 0.692490\n",
      "Train Epoch: 3 [340/700 (49%)]\tLoss: 0.660828\n",
      "Train Epoch: 3 [360/700 (51%)]\tLoss: 0.693371\n",
      "Train Epoch: 3 [380/700 (54%)]\tLoss: 0.645891\n",
      "Train Epoch: 3 [400/700 (57%)]\tLoss: 0.693363\n",
      "Train Epoch: 3 [420/700 (60%)]\tLoss: 0.773665\n",
      "Train Epoch: 3 [440/700 (63%)]\tLoss: 0.620362\n",
      "Train Epoch: 3 [460/700 (66%)]\tLoss: 0.622347\n",
      "Train Epoch: 3 [480/700 (69%)]\tLoss: 0.530247\n",
      "Train Epoch: 3 [500/700 (71%)]\tLoss: 0.686673\n",
      "Train Epoch: 3 [520/700 (74%)]\tLoss: 0.905631\n",
      "Train Epoch: 3 [540/700 (77%)]\tLoss: 0.697826\n",
      "Train Epoch: 3 [560/700 (80%)]\tLoss: 0.622603\n",
      "Train Epoch: 3 [580/700 (83%)]\tLoss: 0.702944\n",
      "Train Epoch: 3 [600/700 (86%)]\tLoss: 0.886679\n",
      "Train Epoch: 3 [620/700 (89%)]\tLoss: 0.616598\n",
      "Train Epoch: 3 [640/700 (91%)]\tLoss: 0.857251\n",
      "Train Epoch: 3 [660/700 (94%)]\tLoss: 0.611263\n",
      "Train Epoch: 3 [680/700 (97%)]\tLoss: 0.536125\n",
      "Train Epoch: 4 [0/700 (0%)]\tLoss: 0.735457\n",
      "Train Epoch: 4 [20/700 (3%)]\tLoss: 0.570016\n",
      "Train Epoch: 4 [40/700 (6%)]\tLoss: 0.607697\n",
      "Train Epoch: 4 [60/700 (9%)]\tLoss: 0.799102\n",
      "Train Epoch: 4 [80/700 (11%)]\tLoss: 0.513425\n",
      "Train Epoch: 4 [100/700 (14%)]\tLoss: 0.805429\n",
      "Train Epoch: 4 [120/700 (17%)]\tLoss: 0.637000\n",
      "Train Epoch: 4 [140/700 (20%)]\tLoss: 0.711700\n",
      "Train Epoch: 4 [160/700 (23%)]\tLoss: 0.603669\n",
      "Train Epoch: 4 [180/700 (26%)]\tLoss: 0.788380\n",
      "Train Epoch: 4 [200/700 (29%)]\tLoss: 0.705057\n",
      "Train Epoch: 4 [220/700 (31%)]\tLoss: 0.508613\n",
      "Train Epoch: 4 [240/700 (34%)]\tLoss: 0.601860\n",
      "Train Epoch: 4 [260/700 (37%)]\tLoss: 0.716492\n",
      "Train Epoch: 4 [280/700 (40%)]\tLoss: 0.525569\n",
      "Train Epoch: 4 [300/700 (43%)]\tLoss: 0.662173\n",
      "Train Epoch: 4 [320/700 (46%)]\tLoss: 0.566428\n",
      "Train Epoch: 4 [340/700 (49%)]\tLoss: 0.574557\n",
      "Train Epoch: 4 [360/700 (51%)]\tLoss: 0.693174\n",
      "Train Epoch: 4 [380/700 (54%)]\tLoss: 0.768076\n",
      "Train Epoch: 4 [400/700 (57%)]\tLoss: 0.739410\n",
      "Train Epoch: 4 [420/700 (60%)]\tLoss: 0.637061\n",
      "Train Epoch: 4 [440/700 (63%)]\tLoss: 0.693149\n",
      "Train Epoch: 4 [460/700 (66%)]\tLoss: 0.702192\n",
      "Train Epoch: 4 [480/700 (69%)]\tLoss: 0.693146\n",
      "Train Epoch: 4 [500/700 (71%)]\tLoss: 0.603771\n",
      "Train Epoch: 4 [520/700 (74%)]\tLoss: 0.496456\n",
      "Train Epoch: 4 [540/700 (77%)]\tLoss: 0.382650\n",
      "Train Epoch: 4 [560/700 (80%)]\tLoss: 0.886497\n",
      "Train Epoch: 4 [580/700 (83%)]\tLoss: 0.505913\n",
      "Train Epoch: 4 [600/700 (86%)]\tLoss: 0.400572\n",
      "Train Epoch: 4 [620/700 (89%)]\tLoss: 0.568825\n",
      "Train Epoch: 4 [640/700 (91%)]\tLoss: 0.835746\n",
      "Train Epoch: 4 [660/700 (94%)]\tLoss: 0.799640\n",
      "Train Epoch: 4 [680/700 (97%)]\tLoss: 0.589661\n",
      "Train Epoch: 5 [0/700 (0%)]\tLoss: 0.975048\n",
      "Train Epoch: 5 [20/700 (3%)]\tLoss: 0.430225\n",
      "Train Epoch: 5 [40/700 (6%)]\tLoss: 0.682709\n",
      "Train Epoch: 5 [60/700 (9%)]\tLoss: 0.580927\n",
      "Train Epoch: 5 [80/700 (11%)]\tLoss: 0.807306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [100/700 (14%)]\tLoss: 0.991527\n",
      "Train Epoch: 5 [120/700 (17%)]\tLoss: 0.741051\n",
      "Train Epoch: 5 [140/700 (20%)]\tLoss: 0.673577\n",
      "Train Epoch: 5 [160/700 (23%)]\tLoss: 0.693147\n",
      "Train Epoch: 5 [180/700 (26%)]\tLoss: 0.377421\n",
      "Train Epoch: 5 [200/700 (29%)]\tLoss: 0.721003\n",
      "Train Epoch: 5 [220/700 (31%)]\tLoss: 0.804444\n",
      "Train Epoch: 5 [240/700 (34%)]\tLoss: 0.342639\n",
      "Train Epoch: 5 [260/700 (37%)]\tLoss: 1.296594\n",
      "Train Epoch: 5 [280/700 (40%)]\tLoss: 0.685365\n",
      "Train Epoch: 5 [300/700 (43%)]\tLoss: 0.693304\n",
      "Train Epoch: 5 [320/700 (46%)]\tLoss: 0.700903\n",
      "Train Epoch: 5 [340/700 (49%)]\tLoss: 0.693163\n",
      "Train Epoch: 5 [360/700 (51%)]\tLoss: 0.568766\n",
      "Train Epoch: 5 [380/700 (54%)]\tLoss: 0.687163\n",
      "Train Epoch: 5 [400/700 (57%)]\tLoss: 0.684522\n",
      "Train Epoch: 5 [420/700 (60%)]\tLoss: 0.981954\n",
      "Train Epoch: 5 [440/700 (63%)]\tLoss: 0.693147\n",
      "Train Epoch: 5 [460/700 (66%)]\tLoss: 0.400699\n",
      "Train Epoch: 5 [480/700 (69%)]\tLoss: 0.534543\n",
      "Train Epoch: 5 [500/700 (71%)]\tLoss: 0.784738\n",
      "Train Epoch: 5 [520/700 (74%)]\tLoss: 0.681366\n",
      "Train Epoch: 5 [540/700 (77%)]\tLoss: 0.916129\n",
      "Train Epoch: 5 [560/700 (80%)]\tLoss: 0.372235\n",
      "Train Epoch: 5 [580/700 (83%)]\tLoss: 0.693147\n",
      "Train Epoch: 5 [600/700 (86%)]\tLoss: 0.693148\n",
      "Train Epoch: 5 [620/700 (89%)]\tLoss: 0.693147\n",
      "Train Epoch: 5 [640/700 (91%)]\tLoss: 0.693147\n",
      "Train Epoch: 5 [660/700 (94%)]\tLoss: 0.488253\n",
      "Train Epoch: 5 [680/700 (97%)]\tLoss: 0.574882\n",
      "Train Epoch: 6 [0/700 (0%)]\tLoss: 0.718708\n",
      "Train Epoch: 6 [20/700 (3%)]\tLoss: 0.693147\n",
      "Train Epoch: 6 [40/700 (6%)]\tLoss: 0.568438\n",
      "Train Epoch: 6 [60/700 (9%)]\tLoss: 0.727482\n",
      "Train Epoch: 6 [80/700 (11%)]\tLoss: 0.402565\n",
      "Train Epoch: 6 [100/700 (14%)]\tLoss: 0.520209\n",
      "Train Epoch: 6 [120/700 (17%)]\tLoss: 0.526860\n",
      "Train Epoch: 6 [140/700 (20%)]\tLoss: 0.440096\n",
      "Train Epoch: 6 [160/700 (23%)]\tLoss: 0.677614\n",
      "Train Epoch: 6 [180/700 (26%)]\tLoss: 0.848098\n",
      "Train Epoch: 6 [200/700 (29%)]\tLoss: 0.570260\n",
      "Train Epoch: 6 [220/700 (31%)]\tLoss: 0.547540\n",
      "Train Epoch: 6 [240/700 (34%)]\tLoss: 0.587353\n",
      "Train Epoch: 6 [260/700 (37%)]\tLoss: 0.916927\n",
      "Train Epoch: 6 [280/700 (40%)]\tLoss: 0.693147\n",
      "Train Epoch: 6 [300/700 (43%)]\tLoss: 0.657037\n",
      "Train Epoch: 6 [320/700 (46%)]\tLoss: 0.574566\n",
      "Train Epoch: 6 [340/700 (49%)]\tLoss: 0.693147\n",
      "Train Epoch: 6 [360/700 (51%)]\tLoss: 0.693147\n",
      "Train Epoch: 6 [380/700 (54%)]\tLoss: 0.846441\n",
      "Train Epoch: 6 [400/700 (57%)]\tLoss: 0.693147\n",
      "Train Epoch: 6 [420/700 (60%)]\tLoss: 0.693147\n",
      "Train Epoch: 6 [440/700 (63%)]\tLoss: 0.647804\n",
      "Train Epoch: 6 [460/700 (66%)]\tLoss: 0.712959\n",
      "Train Epoch: 6 [480/700 (69%)]\tLoss: 0.693147\n",
      "Train Epoch: 6 [500/700 (71%)]\tLoss: 0.684436\n",
      "Train Epoch: 6 [520/700 (74%)]\tLoss: 0.543284\n",
      "Train Epoch: 6 [540/700 (77%)]\tLoss: 0.810948\n",
      "Train Epoch: 6 [560/700 (80%)]\tLoss: 0.944285\n",
      "Train Epoch: 6 [580/700 (83%)]\tLoss: 0.532866\n",
      "Train Epoch: 6 [600/700 (86%)]\tLoss: 0.958083\n",
      "Train Epoch: 6 [620/700 (89%)]\tLoss: 0.693147\n",
      "Train Epoch: 6 [640/700 (91%)]\tLoss: 0.571110\n",
      "Train Epoch: 6 [660/700 (94%)]\tLoss: 0.705917\n",
      "Train Epoch: 6 [680/700 (97%)]\tLoss: 0.696909\n",
      "Train Epoch: 7 [0/700 (0%)]\tLoss: 1.003612\n",
      "Train Epoch: 7 [20/700 (3%)]\tLoss: 0.693147\n",
      "Train Epoch: 7 [40/700 (6%)]\tLoss: 0.682485\n",
      "Train Epoch: 7 [60/700 (9%)]\tLoss: 0.525514\n",
      "Train Epoch: 7 [80/700 (11%)]\tLoss: 0.693147\n",
      "Train Epoch: 7 [100/700 (14%)]\tLoss: 0.521886\n",
      "Train Epoch: 7 [120/700 (17%)]\tLoss: 0.899425\n",
      "Train Epoch: 7 [140/700 (20%)]\tLoss: 0.685317\n",
      "Train Epoch: 7 [160/700 (23%)]\tLoss: 0.939234\n",
      "Train Epoch: 7 [180/700 (26%)]\tLoss: 0.499117\n",
      "Train Epoch: 7 [200/700 (29%)]\tLoss: 0.684734\n",
      "Train Epoch: 7 [220/700 (31%)]\tLoss: 0.688127\n",
      "Train Epoch: 7 [240/700 (34%)]\tLoss: 0.706309\n",
      "Train Epoch: 7 [260/700 (37%)]\tLoss: 0.787902\n",
      "Train Epoch: 7 [280/700 (40%)]\tLoss: 0.411470\n",
      "Train Epoch: 7 [300/700 (43%)]\tLoss: 0.693147\n",
      "Train Epoch: 7 [320/700 (46%)]\tLoss: 0.771280\n",
      "Train Epoch: 7 [340/700 (49%)]\tLoss: 0.649204\n",
      "Train Epoch: 7 [360/700 (51%)]\tLoss: 0.672884\n",
      "Train Epoch: 7 [380/700 (54%)]\tLoss: 0.414921\n",
      "Train Epoch: 7 [400/700 (57%)]\tLoss: 0.551427\n",
      "Train Epoch: 7 [420/700 (60%)]\tLoss: 0.715079\n",
      "Train Epoch: 7 [440/700 (63%)]\tLoss: 0.882763\n",
      "Train Epoch: 7 [460/700 (66%)]\tLoss: 0.512504\n",
      "Train Epoch: 7 [480/700 (69%)]\tLoss: 0.694753\n",
      "Train Epoch: 7 [500/700 (71%)]\tLoss: 0.366841\n",
      "Train Epoch: 7 [520/700 (74%)]\tLoss: 0.641470\n",
      "Train Epoch: 7 [540/700 (77%)]\tLoss: 0.557413\n",
      "Train Epoch: 7 [560/700 (80%)]\tLoss: 0.920644\n",
      "Train Epoch: 7 [580/700 (83%)]\tLoss: 0.346680\n",
      "Train Epoch: 7 [600/700 (86%)]\tLoss: 0.831560\n",
      "Train Epoch: 7 [620/700 (89%)]\tLoss: 0.504656\n",
      "Train Epoch: 7 [640/700 (91%)]\tLoss: 0.351079\n",
      "Train Epoch: 7 [660/700 (94%)]\tLoss: 0.833359\n",
      "Train Epoch: 7 [680/700 (97%)]\tLoss: 0.888849\n",
      "Train Epoch: 8 [0/700 (0%)]\tLoss: 0.658063\n",
      "Train Epoch: 8 [20/700 (3%)]\tLoss: 0.694838\n",
      "Train Epoch: 8 [40/700 (6%)]\tLoss: 0.685224\n",
      "Train Epoch: 8 [60/700 (9%)]\tLoss: 0.693218\n",
      "Train Epoch: 8 [80/700 (11%)]\tLoss: 0.849044\n",
      "Train Epoch: 8 [100/700 (14%)]\tLoss: 0.565345\n",
      "Train Epoch: 8 [120/700 (17%)]\tLoss: 0.693147\n",
      "Train Epoch: 8 [140/700 (20%)]\tLoss: 0.697863\n",
      "Train Epoch: 8 [160/700 (23%)]\tLoss: 0.505683\n",
      "Train Epoch: 8 [180/700 (26%)]\tLoss: 0.788393\n",
      "Train Epoch: 8 [200/700 (29%)]\tLoss: 0.524496\n",
      "Train Epoch: 8 [220/700 (31%)]\tLoss: 0.499649\n",
      "Train Epoch: 8 [240/700 (34%)]\tLoss: 0.816595\n",
      "Train Epoch: 8 [260/700 (37%)]\tLoss: 0.319693\n",
      "Train Epoch: 8 [280/700 (40%)]\tLoss: 0.503253\n",
      "Train Epoch: 8 [300/700 (43%)]\tLoss: 0.421616\n",
      "Train Epoch: 8 [320/700 (46%)]\tLoss: 0.508607\n",
      "Train Epoch: 8 [340/700 (49%)]\tLoss: 0.693147\n",
      "Train Epoch: 8 [360/700 (51%)]\tLoss: 0.693147\n",
      "Train Epoch: 8 [380/700 (54%)]\tLoss: 0.693147\n",
      "Train Epoch: 8 [400/700 (57%)]\tLoss: 0.611581\n",
      "Train Epoch: 8 [420/700 (60%)]\tLoss: 0.693147\n",
      "Train Epoch: 8 [440/700 (63%)]\tLoss: 0.497225\n",
      "Train Epoch: 8 [460/700 (66%)]\tLoss: 0.693147\n",
      "Train Epoch: 8 [480/700 (69%)]\tLoss: 0.521484\n",
      "Train Epoch: 8 [500/700 (71%)]\tLoss: 0.458915\n",
      "Train Epoch: 8 [520/700 (74%)]\tLoss: 1.001830\n",
      "Train Epoch: 8 [540/700 (77%)]\tLoss: 1.126001\n",
      "Train Epoch: 8 [560/700 (80%)]\tLoss: 0.503441\n",
      "Train Epoch: 8 [580/700 (83%)]\tLoss: 1.002994\n",
      "Train Epoch: 8 [600/700 (86%)]\tLoss: 1.003190\n",
      "Train Epoch: 8 [620/700 (89%)]\tLoss: 0.874099\n",
      "Train Epoch: 8 [640/700 (91%)]\tLoss: 0.524973\n",
      "Train Epoch: 8 [660/700 (94%)]\tLoss: 0.503458\n",
      "Train Epoch: 8 [680/700 (97%)]\tLoss: 0.510995\n",
      "Train Epoch: 9 [0/700 (0%)]\tLoss: 0.512099\n",
      "Train Epoch: 9 [20/700 (3%)]\tLoss: 0.643259\n",
      "Train Epoch: 9 [40/700 (6%)]\tLoss: 0.693147\n",
      "Train Epoch: 9 [60/700 (9%)]\tLoss: 0.699672\n",
      "Train Epoch: 9 [80/700 (11%)]\tLoss: 0.694194\n",
      "Train Epoch: 9 [100/700 (14%)]\tLoss: 0.848049\n",
      "Train Epoch: 9 [120/700 (17%)]\tLoss: 0.693147\n",
      "Train Epoch: 9 [140/700 (20%)]\tLoss: 0.693147\n",
      "Train Epoch: 9 [160/700 (23%)]\tLoss: 0.693147\n",
      "Train Epoch: 9 [180/700 (26%)]\tLoss: 0.504082\n",
      "Train Epoch: 9 [200/700 (29%)]\tLoss: 0.674505\n",
      "Train Epoch: 9 [220/700 (31%)]\tLoss: 0.693147\n",
      "Train Epoch: 9 [240/700 (34%)]\tLoss: 0.327694\n",
      "Train Epoch: 9 [260/700 (37%)]\tLoss: 0.513030\n",
      "Train Epoch: 9 [280/700 (40%)]\tLoss: 0.518642\n",
      "Train Epoch: 9 [300/700 (43%)]\tLoss: 0.691082\n",
      "Train Epoch: 9 [320/700 (46%)]\tLoss: 0.693147\n",
      "Train Epoch: 9 [340/700 (49%)]\tLoss: 0.546095\n",
      "Train Epoch: 9 [360/700 (51%)]\tLoss: 0.622735\n",
      "Train Epoch: 9 [380/700 (54%)]\tLoss: 0.689644\n",
      "Train Epoch: 9 [400/700 (57%)]\tLoss: 0.551232\n",
      "Train Epoch: 9 [420/700 (60%)]\tLoss: 0.512590\n",
      "Train Epoch: 9 [440/700 (63%)]\tLoss: 0.720836\n",
      "Train Epoch: 9 [460/700 (66%)]\tLoss: 0.535048\n",
      "Train Epoch: 9 [480/700 (69%)]\tLoss: 0.972047\n",
      "Train Epoch: 9 [500/700 (71%)]\tLoss: 0.503204\n",
      "Train Epoch: 9 [520/700 (74%)]\tLoss: 0.647924\n",
      "Train Epoch: 9 [540/700 (77%)]\tLoss: 0.692909\n",
      "Train Epoch: 9 [560/700 (80%)]\tLoss: 0.676295\n",
      "Train Epoch: 9 [580/700 (83%)]\tLoss: 0.542397\n",
      "Train Epoch: 9 [600/700 (86%)]\tLoss: 0.344031\n",
      "Train Epoch: 9 [620/700 (89%)]\tLoss: 0.507771\n",
      "Train Epoch: 9 [640/700 (91%)]\tLoss: 0.353375\n",
      "Train Epoch: 9 [660/700 (94%)]\tLoss: 0.421585\n",
      "Train Epoch: 9 [680/700 (97%)]\tLoss: 0.694327\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        resized_target = target.view(output.shape[0], -1)\n",
    "        loss = criterion(output, resized_target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "classes = (True, False)\n",
    "\n",
    "def boolean_output(output):\n",
    "    return bool(output.view(1) > torch.tensor([0.5]))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            bool_output = boolean_output(output)\n",
    "            bool_target = bool(target)\n",
    "            y_test.append(bool_target)\n",
    "            y_pred.append(bool_output)\n",
    "            if bool_output == bool_target:\n",
    "                correct += 1\n",
    "    accuracy = correct/len(test_loader.dataset)\n",
    "    print(f\"accuracy: {accuracy}\")\n",
    "    # Confusion matrix\n",
    "    confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(confusion_mtx, classes=classes, normalize=True,\n",
    "                          title='Confusion matrix')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6764705882352942\n",
      "[[37  4]\n",
      " [18  9]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(model, \"cpu\", test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
